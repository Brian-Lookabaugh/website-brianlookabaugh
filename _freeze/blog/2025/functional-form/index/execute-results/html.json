{
  "hash": "6e8c92b8fa37991e3e73ce8a954820e9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The Overlooked Part of Confounder Adjustment\"\ndate: 2025-06-08\ndescription: \"Obviously, we all know that we need to adjust for confounders, but what happens when we don't adjust for them the right way?\"\nimage: \"figures/funcform.png\"\ntoc: true\nexecute:\n  warning: false\n  error: false\n  message: false\ntoc-location: \"left\"\ntoc-title: \"Contents\"\ncategories:\n  - causal inference\n  - regression\n---\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Load Libraries\npacman::p_load(\n  \"dplyr\", # Data Manipulation\n  \"ggplot2\", # Data Visualization\n  \"tidyr\", # Re-Shaping\n  \"scales\", # Scaling Visualizations\n  \"ggtext\", # Colored Text in Plots\n  \"gt\", # Nice Tables\n  install = FALSE\n)\n\n# Define a Custom Theme\nblog_theme <- function() {\n  theme_bw() +  \n    theme(\n      panel.grid.major = element_line(color = \"gray80\", size = 0.3),\n      panel.grid.minor = element_blank(),\n      panel.border = element_blank(),\n      plot.background = element_rect(fill = \"white\", color = NA),\n      plot.title = element_text(face = \"bold\", size = 16, margin = margin(t = 0, r = 0, b = 15, l = 0)),\n      axis.title.x = element_text(face = \"bold\", size = 14, margin = margin(t = 15, r = 0, b = 0, l = 0)),\n      axis.title.y = element_text(face = \"bold\", size = 14, margin = margin(t = 0, r = 15, b = 0, l = 0)),\n      strip.text = element_text(face = \"bold\"),\n      axis.text.x = element_text(face = \"bold\", size = 10), \n      axis.text.y = element_text(face = \"bold\", size = 10), \n      axis.ticks.x = element_blank(), \n      axis.ticks.y = element_blank(), \n      strip.background = element_rect(fill = \"grey80\", color = NA),\n      legend.title = element_text(face = \"bold\", size = 14),\n      legend.text = element_text(face = \"bold\", size = 10, color = \"grey25\"),\n    )\n}\n\n# Establish a Custom Color Scheme\ncolors <- c(\n  \"1\" = \"#133a29\",\n  \"2\" = \"#ab3d29\",\n  \"3\" = \"#f9ba6d\",\n  \"4\" = \"#314318\",\n  \"5\" = \"#63221f\"\n)\n```\n:::\n\n\n\n# Intro\n\nI want to start this blog off acknowledging that this blog is exploratory for myself. I am not and will not be attempting to \"teach\" or anything like that in this post. However, the blog format is a helpful way for me to get my hands dirty and learn something new so, read at your own peril, but also, join me for the journey.\n\nIf you've read my posts before (or are familiar with the causal inference literature... if not, read [this blog I wrote](https://brian-lookabaugh.github.io/website-brianlookabaugh/blog/2024/causal-inference-simulation/), then you know that adjusting for confounders is something you need to do if you're not running an experiment (for the most part).\n\nLess appreciated, although always mentioned, is the *modeling* side of things. That is, because we work with statistical models that have their own assumptions, we need to make sure that, in addition to adjusting for confounders, we also adjust for their correct functional form. But, I've always wondered, how consequential is it to adjust for a confounder assuming an entirely linear relationship *if* the actual relationship between a confounder and the outcome is non-linear?\n\nWell, that is the entire point of this post. I'm really curious to see how, within this limited example, how the bias changes between an inclusion of a necessary control variable (misspecified) and the inclusion of the control variable correctly specified. I'm going to look at four different scenarios in the process.\n\nFirst, I'll take a look at a squared effect, which looks something like the following:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nset.seed(1234)\n\nn_obs <- 10000\nexposure_effect <- 1.5\n  \n  for (i in 1:1000) {\n    # Vary the Linear Effect of Z Between 1% and 300% of the Exposure Effect\n    z_linear_effect <- runif(1, 0.01, 3) * 1.5\n    # Make the Curvilinear Effect Always 50% of the Linear Effect\n    z_curv_effect <- 0.5 * z_linear_effect\n    \n    # Generate Variables\n    Z <- rnorm(n_obs, 0, 1)             \n    X <- 0.5 * Z + rnorm(n_obs, 0, 1)   \n    Y <- exposure_effect * X + z_linear_effect * Z + z_curv_effect * Z^2 + rnorm(n_obs, 0, 1)\n  }\n\nsquared_df <- data.frame(Z = Z, Y = Y)\n\nggplot(squared_df, aes(x = Z, y = Y)) +\n  geom_point(alpha = 0.1, size = 0.8, color = \"#133a29\") +\n  geom_smooth(method = \"loess\", se = FALSE, size = 1.5, color = \"#ab3d29\") +\n  xlim(-4, 4) +\n  labs(\n    x = \"Z\",\n    y = \"Y\"\n  ) +\n  blog_theme()\n```\n\n::: {.cell-output-display}\n![Quadratic Confounder-Outcome Effect](index_files/figure-html/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\nThen, I'll take a look at another polynomial, examining a cubic effect instead:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nset.seed(1234)\n\nn_obs <- 10000\nexposure_effect <- 1.5\n\n  for (i in 1:1000) {\n    # Vary the Linear Effect of Z Between 1% and 300% of the Exposure Effect\n    z_linear_effect <- runif(1, 0.01, 3) * exposure_effect\n    # Make the Squared Effect Always 50% of the Linear Effect\n    z_squared_effect <- 0.5 * z_linear_effect\n    # Make the Cubed Effect Always 50% of the Squared Effect\n    z_cubed_effect <- 0.5 * z_squared_effect\n    \n    # Generate Variables\n    Z <- rnorm(n_obs, 0, 1)             \n    X <- 0.5 * Z + rnorm(n_obs, 0, 1)   \n    Y <- exposure_effect * X + z_linear_effect * Z + z_squared_effect * Z^2 +\n         z_cubed_effect * Z^3 + rnorm(n_obs, 0, 1)\n  }\n\ncubed_df <- data.frame(Z = Z, Y = Y)\n\nggplot(cubed_df, aes(x = Z, y = Y)) +\n  geom_point(alpha = 0.1, size = 0.8, color = \"#133a29\") +\n  geom_smooth(method = \"loess\", se = FALSE, size = 1, color = \"#ab3d29\") +\n  xlim(-4, 4) +\n  labs(\n    x = \"Z\",\n    y = \"Y\"\n  ) +\n  blog_theme()\n```\n\n::: {.cell-output-display}\n![Cubic Confounder-Outcome Effect](index_files/figure-html/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\nThen, I'll shift away from polynomials and take a look at interaction effects. First, I'll dive into interaction effects where the interaction effect remains fixed but the main effect varies, then I'll do the inverse, fixing the main effect constant but letting the interaction effect vary. Regardless, either situation could produce a confounder-outcome effect that looks like this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nset.seed(1234)\n\nn_obs <- 10000\nexposure_effect <- 1.5\n\n  for (i in 1:1000) {\n    # Fixed Interaction Effect\n    interaction_effect <- 1\n  \n    # Vary Main Effect of Z\n    z_main_effect <- runif(1, 0.01, 3) * exposure_effect\n  \n    # Generate Variables\n    Z <- rnorm(n_obs, 0, 1)\n    X <- 0.5 * Z + rnorm(n_obs, 0, 1)\n    Y <- exposure_effect * X + z_main_effect * Z + interaction_effect * X * Z + rnorm(n_obs, 0, 1)\n  }\n\ninteraction_df <- data.frame(Z = Z, Y = Y, X = X)\n\n# Create Artificial Cut-Off Points for X to See How the Z Effect on Y Varies Across X Levels\ninteraction_df <- interaction_df %>%\n     mutate(X_bin = cut(X,breaks = quantile(X, probs = c(0, 1/3, 2/3, 1)),\n                        labels = c(\"Low X\", \"Medium X\", \"High X\"),\n                        include.lowest = TRUE))\n\nggplot(interaction_df, aes(x = Z, y = Y)) +\n  geom_point(alpha = 0.1, size = 0.8, color = \"#133a29\") +\n  geom_smooth(method = \"lm\", se = FALSE, size = 1, color = \"#ab3d29\") +\n  xlim(-4, 4) +\n  facet_wrap(~X_bin) +\n  labs(\n    x = \"Z\",\n    y = \"Y\"\n  ) +\n  blog_theme()\n```\n\n::: {.cell-output-display}\n![Confounder-Outcome Effect That Interacts with the Exposure](index_files/figure-html/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n# Squared Confounder-Outcome Simulation\n\nStarting off, the following simulation code seeks to answer, \"if we kept the squared effect of $Z$ on $Y$ constant, but let the linear component of the $Z \\rightarrow Y$ effect vary from 0.1x the size of the $X \\rightarrow Y$ effect to 3x the size of the $X \\rightarrow Y$ effect, how much bias do we see if we 1) omit the confounder entirely, 2) include the confounder but only specify it linearly, and 3) include the confounder and specify its correct functional form\"? \n\nOkay, that's a long question, but we can summarize it as \"if we generated data ($n$ = 1000) 10,000 times, and let the linear confounder effect/exposure effect vary, specify different models that are increasingly wrong, how much bias do we get?\"\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a Function to Estimate Consequences of Misspecification for A Lot of Runs and Different Scenarios\nsquared_effect_dgp <- function(n_runs = 10000, n_obs = 1000, exposure_effect = 1.5) {\n  \n  set.seed(1234)\n  \n  # Store Results\n  results <- data.frame(\n    sim = 1:n_runs,\n    z_effect_ratio = NA,\n    model1_effect = NA, # Omits Z\n    model2_effect = NA, # Includes Z Without Functional Form\n    model3_effect = NA, # Includes Z with Functional Form\n    model1_bias = NA, \n    model2_bias = NA,\n    model3_bias = NA\n  )\n  \n  for (i in 1:n_runs) {\n    # Vary the Linear Effect of Z Between 1% and 300% of the Exposure Effect\n    z_linear_effect <- runif(1, 0.01, 3) * exposure_effect\n    # Make the Curvilinear Effect Always 50% of the Linear Effect\n    z_curv_effect <- 0.5 * z_linear_effect\n    \n    # Generate Variables\n    Z <- rnorm(n_obs, 0, 1)             \n    X <- 0.5 * Z + rnorm(n_obs, 0, 1)   \n    Y <- exposure_effect * X + z_linear_effect * Z + z_curv_effect * Z^2 + rnorm(n_obs, 0, 1)\n    \n    # Model 1: Omits Z\n    model1 <- lm(Y ~ X)\n    # Model 2: Includes Z Without Functional Form\n    model2 <- lm(Y ~ X + Z)\n    # Model 3: Includes Z with Functional Form\n    model3 <- lm(Y ~ X + Z + I(Z^2))\n    \n    # Extract X Coefficients\n    est1 <- coef(model1)[\"X\"]\n    est2 <- coef(model2)[\"X\"]\n    est3 <- coef(model3)[\"X\"]\n    results$z_effect_ratio[i] <- z_linear_effect / exposure_effect\n    \n    results$model1_bias[i] <- est1 - exposure_effect\n    results$model2_bias[i] <- est2 - exposure_effect\n    results$model3_bias[i] <- est3 - exposure_effect\n  }\n  \n  return(results)\n}\n\n# Run the Function\nsquared_effect_dgp_results <- squared_effect_dgp(n_runs = 10000, n_obs = 1000, exposure_effect = 1.5)\n\n# Plot the Results\nggplot(squared_effect_dgp_results, aes(x = z_effect_ratio)) +\n  geom_point(aes(y = model1_bias, color = \"Model 1: Omits Z\"), alpha = 0.2, size = 0.8) +\n  geom_point(aes(y = model2_bias, color = \"Model 2: Linear Z Only\"), alpha = 0.2, size = 0.8) +\n  geom_point(aes(y = model3_bias, color = \"Model 3: Z and Z²\"), alpha = 0.2, size = 0.8) +\n  scale_color_manual(values = c(\"Model 1: Omits Z\" = \"#63221f\",\n                                \"Model 2: Linear Z Only\" = \"#ab3d29\",\n                                \"Model 3: Z and Z²\" = \"#133a29\")) +\n  labs(\n    title = \"\",\n    subtitle = \"On average <b><span style='color:#63221f'>omitting Z</span></b> results in bias that grows in one direction while <b><span style='color:#ab3d29'>including Z linearly</span></b> creates bias<br>that spreads in both a negative and a positive direction while <b><span style='color:#133a29'>including Z and specifying its<br>non-linear effect</span></b> results in practically no bias.\",\n    x = \"Size of the Linear Z Effect on Y Relative to the X Effect on Y\",\n    y = \"Bias\",\n    color = \"\"\n  ) +\n  blog_theme() +\n  theme(legend.position = \"none\",\n        plot.subtitle = ggtext::element_markdown(size = 11))\n```\n\n::: {.cell-output-display}\n![Bias When Excluding a Squared Effect](index_files/figure-html/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\nCool! What do we see from this? Well, obviously, no matter how large our confounder effect / exposure effect ratio is, as long as we specify our model right. there's basically no bias, with random variation creating any very small deviations from zero bias. \n\nOn the other side of the things, as we increase the linear confounder effect / exposure effect ratio for the model excluding $Z$ entirely, the bias increases linearly in a positive manner. This is pretty intuitive when you think about it. If the effect of $Z$ is actually really small, then any residual confounding when we *don't* control for it will also be small. So very intuitive but also kind of obvious.\n\nWhat is more interesting is the model where we *include* $Z$ but *do not* specify its correct functional form. As we see, if the size of the confounder effect on $Y$ is about equal to the exposure effect on $Y$ or is maybe even smaller, then not specifying the functional form of $Z$ correctly (at least in this scenario) isn't that big of a deal. But, as the confounder effect grows, so too does the bias of a functional form mis-specification (in both a positive and negative direction). Still, the bias is not anywhere near as severe as the entire exclusion of $Z$ from the model.\n\n# Cubed Confounder-Outcome Simulation\n\nHere, I'm doing the exact same thing (keeping the polynomial effects fixed and varying the linear effect) but I'm spicing things up with a $Z^3$ effect in addition to the $Z^2$ effect.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a Function to Estimate Consequences of Misspecification for A Lot of Runs and Different Scenarios\ncubed_effect_dgp <- function(n_runs = 10000, n_obs = 1000, exposure_effect = 1.5) {\n  \n  set.seed(1234)\n  \n  # Store Results\n  results <- data.frame(\n    sim = 1:n_runs,\n    z_effect_ratio = NA,\n    model1_effect = NA, # Omits Z\n    model2_effect = NA, # Includes Z Without Functional Forms\n    model3_effect = NA, # Includes Z with Squared Functional Form\n    model4_effect = NA, # Includes Z with All Functional Forms\n    model1_bias = NA, \n    model2_bias = NA,\n    model3_bias = NA\n  )\n  \n  for (i in 1:n_runs) {\n    # Vary the Linear Effect of Z Between 1% and 300% of the Exposure Effect\n    z_linear_effect <- runif(1, 0.01, 3) * exposure_effect\n    # Make the Squared Effect Always 50% of the Linear Effect\n    z_squared_effect <- 0.5 * z_linear_effect\n    # Make the Cubed Effect Always 50% of the Squared Effect\n    z_cubed_effect <- 0.5 * z_squared_effect\n    \n    # Generate Variables\n    Z <- rnorm(n_obs, 0, 1)             \n    X <- 0.5 * Z + rnorm(n_obs, 0, 1)   \n    Y <- exposure_effect * X + z_linear_effect * Z + z_squared_effect * Z^2 +\n         z_cubed_effect * Z^3 + rnorm(n_obs, 0, 1)\n    \n    # Model 1: Omits Z\n    model1 <- lm(Y ~ X)\n    # Model 2: Includes Z Without Functional Forms\n    model2 <- lm(Y ~ X + Z)\n    # Model 3: Includes Z with Squared Functional Form\n    model3 <- lm(Y ~ X + Z + I(Z^2))\n    # Model 4: Includes Z with All Functional Forms\n    model4 <- lm(Y ~ X + Z + I(Z^2) + I(Z^3))\n    \n    # Extract X Coefficients\n    est1 <- coef(model1)[\"X\"]\n    est2 <- coef(model2)[\"X\"]\n    est3 <- coef(model3)[\"X\"]\n    est4 <- coef(model4)[\"X\"]\n    results$z_effect_ratio[i] <- z_linear_effect / exposure_effect\n    \n    results$model1_bias[i] <- est1 - exposure_effect\n    results$model2_bias[i] <- est2 - exposure_effect\n    results$model3_bias[i] <- est3 - exposure_effect\n    results$model4_bias[i] <- est4 - exposure_effect\n  }\n  \n  return(results)\n}\n\n# Run the Function\ncubed_effect_dgp_results <- cubed_effect_dgp(n_runs = 10000, n_obs = 1000, exposure_effect = 1.5)\n\n# Plot the Results\nggplot(cubed_effect_dgp_results, aes(x = z_effect_ratio)) +\n  geom_point(aes(y = model1_bias, color = \"Model 1: Omits Z\"), alpha = 0.2, size = 0.8) +\n  geom_point(aes(y = model2_bias, color = \"Model 2: Linear Z Only\"), alpha = 0.2, size = 0.8) +\n  geom_point(aes(y = model3_bias, color = \"Model 3: Z and Z²\"), alpha = 0.2, size = 0.8) +\n  geom_point(aes(y = model4_bias, color = \"Model 4: Z and Z² and Z³\"), alpha = 0.2, size = 0.8) +\n  scale_color_manual(values = c(\"Model 1: Omits Z\" = \"#63221f\",\n                                \"Model 2: Linear Z Only\" = \"#ab3d29\",\n                                \"Model 3: Z and Z²\" = \"#f9ba6d\",\n                                \"Model 4: Z and Z² and Z³\" = \"#133a29\")) +\n  labs(\n    title = \"\",\n    subtitle = \"On average <b><span style='color:#63221f'>omitting Z</span></b> results in bias that grows in one direction while <b><span style='color:#ab3d29'>including Z linearly</span></b> creates bias<br>that spreads in both a negative and a positive direction which is slighy reduced when <b><span style='color:#f9ba6d'>a squared term for Z<br>is introduced</span></b> while <b><span style='color:#133a29'>including Z and specifying all its non-linear effects</span></b> results in practically no bias.\",\n    x = \"Size of the Linear Z Effect on Y Relative to the X Effect on Y\",\n    y = \"Bias\",\n    color = \"\"\n  ) +\n  blog_theme() +\n  theme(legend.position = \"none\",\n        plot.subtitle = ggtext::element_markdown(size = 11))\n```\n\n::: {.cell-output-display}\n![Bias When Excluding a Cubed Effect](index_files/figure-html/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\nAnd, as you can see, adding a cubed effect doesn't change much (again, please keep in mind that I'm fixing the polynomial effects and that this simulation exercise is not systematic... there's a lot of nuance here that I'm not covering). The biggest gap in bias is the total failure to adjust for $Z$ entirely. Bias increases as the confounder effect size grows and confounder effects are mis-specified, but adding polynomials helps reduce the bias.\n\nOne thing that might go unnoticed though is the y-axis here. Look at how it goes up to 4 instead of 2 (like the squared effect)! The exposure effect in the squared and cubed effect remains the same, but the bias has increased by about double on the extreme end of the confounder effect / exposure effect size. I'm not really sure why, and there's a chance I've built this into the data generating process without realizing, but that's also interesting. Well, interesting to a point... we would never worry about that much bias if we already knew about $Z$ and to adjust for it in the first place. Again, adjusting for $Z$ without specifying any polynomials still results bias but dramatically less.\n\n# Interactive Confounder-Outcome Simulation (Varying Main Effect)\n\nNext, I'm moving away from polynomials and shifting to interaction effects. Here, the main effect is varying but the interaction effect is remaining constant.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninteraction_dgp_varying_z_main <- function(n_runs = 10000, n_obs = 1000, exposure_effect = 1.5) {\n  set.seed(1234)\n  \n  results <- data.frame(\n    sim = 1:n_runs,\n    z_effect_ratio = NA,\n    model1_effect = NA,  # Omits Z\n    model2_effect = NA,  # Includes Z only\n    model3_effect = NA,  # Includes Z and X:Z\n    model1_bias = NA,\n    model2_bias = NA,\n    model3_bias = NA\n  )\n  \n  for (i in 1:n_runs) {\n    # Keep the Interaction Effect Fixed\n    interaction_effect <- 1\n    \n    # Vary the Main Effect of Z\n    z_main_effect <- runif(1, 0.01, 3) * exposure_effect\n    \n    # Generate Variables\n    Z <- rnorm(n_obs, 0, 1)\n    X <- 0.5 * Z + rnorm(n_obs, 0, 1)\n    Y <- exposure_effect * X + z_main_effect * Z + interaction_effect * X * Z + rnorm(n_obs, 0, 1)\n    \n    # Models\n    model1 <- lm(Y ~ X)      \n    model2 <- lm(Y ~ X + Z)            \n    model3 <- lm(Y ~ X + Z + X:Z)        \n    \n    # Extract X Coefficients\n    est1 <- coef(model1)[\"X\"]\n    est2 <- coef(model2)[\"X\"]\n    est3 <- coef(model3)[\"X\"]\n    \n    # Store Results\n    results$z_effect_ratio[i] <- z_main_effect / exposure_effect\n    results$model1_bias[i] <- est1 - exposure_effect\n    results$model2_bias[i] <- est2 - exposure_effect\n    results$model3_bias[i] <- est3 - exposure_effect\n  }\n  \n  return(results)\n}\n\ninteraction_results_varying_z_main <- interaction_dgp_varying_z_main(n_runs = 10000, n_obs = 1000, exposure_effect = 1.5)\n\nggplot(interaction_results_varying_z_main, aes(x = z_effect_ratio)) +\n  geom_point(aes(y = model1_bias, color = \"Model 1: Omits Z\"), alpha = 0.2, size = 0.8) +\n  geom_point(aes(y = model2_bias, color = \"Model 2: Adds Z Only\"), alpha = 0.2, size = 0.8) +\n  geom_point(aes(y = model3_bias, color = \"Model 3: Adds Z and Interaction\"), alpha = 0.2, size = 0.8) +\n  scale_color_manual(values = c(\n    \"Model 1: Omits Z\" = \"#63221f\",\n    \"Model 2: Adds Z Only\" = \"#ab3d29\",\n    \"Model 3: Adds Z and Interaction\" = \"#133a29\"\n  )) +\n  labs(\n    title = \"\",\n    subtitle = \"On average <b><span style='color:#63221f'>omitting Z</span></b> results in bias that grows in one direction while <b><span style='color:#ab3d29'>including Z linearly</span></b> creates bias in<br>both a negative and a positive direction while <b><span style='color:#133a29'>including Z and specifying the interactive effect</span></b> results<br>in practically no bias.\",\n    x = \"Size of the Main Z Effect on Y Relative to the X Effect on Y\",\n    y = \"Bias\",\n    color = \"\"\n  )  +\n  blog_theme() +\n  theme(legend.position = \"none\",\n        plot.subtitle = ggtext::element_markdown(size = 11))\n```\n\n::: {.cell-output-display}\n![Bias When Excluding an Interaction Effect with the Main Effect Varying](index_files/figure-html/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n\nIt looks very familiar to the cubed effect simulation exercise. But, a key difference here is the size of the bias across the x-axis for the model that includes the confounder but mis-specifies its effect on $Y$. It's basically constant across the entire range of the confounder effect / exposure effect ratio. Substantively, at least for this data generating process, it means that, on average, a failure to specify an interactive effect for $Z$ results in the same bias regardless of how large the confounder effect / exposure effect ratio is.\n\n# Interactive Confounder-Outcome Simulation (Varying Interactive Effect)\n\nAnd lastly, I'll be taking a look at the consequences of failing to adjust for an interactive effect where the main effect size is fixed but the interaction effect is changing.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninteraction_dgp_varying_z_interaction <- function(n_runs = 10000, n_obs = 1000, exposure_effect = 1.5) {\n  set.seed(1234)\n  \n  results <- data.frame(\n    sim = 1:n_runs,\n    z_effect_ratio = NA,\n    model1_effect = NA, # Omits Z\n    model2_effect = NA, # Includes Z\n    model3_effect = NA, # Includes Z and X:Z\n    model1_bias = NA,\n    model2_bias = NA,\n    model3_bias = NA\n  )\n  \n  for (i in 1:n_runs) {\n    # Vary Interaction Effect Size Relative to the Exposure Effect \n    interaction_effect <- runif(1, 0.01, 3) * exposure_effect\n    \n    # Keep the Main Effect Constant\n    z_main_effect <- 1\n    \n    # Generate Variables\n    Z <- rnorm(n_obs, 0, 1)\n    X <- 0.5 * Z + rnorm(n_obs, 0, 1)\n    Y <- exposure_effect * X + z_main_effect * Z + interaction_effect * X * Z + rnorm(n_obs, 0, 1)\n    \n    # Fit models\n    model1 <- lm(Y ~ X)\n    model2 <- lm(Y ~ X + Z)\n    model3 <- lm(Y ~ X + Z + X:Z)\n    \n    # Extract X Coefficients\n    est1 <- coef(model1)[\"X\"]\n    est2 <- coef(model2)[\"X\"]\n    est3 <- coef(model3)[\"X\"]\n    \n    # Store results\n    results$z_effect_ratio[i] <- interaction_effect / exposure_effect\n    results$model1_bias[i] <- est1 - exposure_effect\n    results$model2_bias[i] <- est2 - exposure_effect\n    results$model3_bias[i] <- est3 - exposure_effect\n  }\n  \n  return(results)\n}\n\ninteraction_results_varying_z_interactive <- interaction_dgp_varying_z_interaction(n_runs = 10000, n_obs = 1000, exposure_effect = 1.5)\n\nggplot(interaction_results_varying_z_interactive, aes(x = z_effect_ratio)) +\n  geom_point(aes(y = model1_bias, color = \"Model 1: Omits Z\"), alpha = 0.2, size = 0.8) +\n  geom_point(aes(y = model2_bias, color = \"Model 2: Adds Z Only\"), alpha = 0.2, size = 0.8) +\n  geom_point(aes(y = model3_bias, color = \"Model 3: Adds Z and Interaction\"), alpha = 0.2, size = 0.8) +\n  scale_color_manual(values = c(\n    \"Model 1: Omits Z\" = \"#63221f\",\n    \"Model 2: Adds Z Only\" = \"#ab3d29\",\n    \"Model 3: Adds Z and Interaction\" = \"#133a29\"\n  )) +\n  labs(\n    title = \"\",\n    subtitle = \"On average <b><span style='color:#63221f'>omitting Z</span></b> results in bias that grows in one direction while <b><span style='color:#ab3d29'>including Z linearly</span></b> creates bias in<br>both a negative and a positive direction while <b><span style='color:#133a29'>including Z and specifying the interactive effect</span></b> results<br>in practically no bias.\",\n    x = \"Size of the Interactive Z Effect on Y Relative to the X Effect on Y\",\n    y = \"Bias\",\n    color = \"\"\n  )  +\n  blog_theme() +\n  theme(legend.position = \"none\",\n        plot.subtitle = ggtext::element_markdown(size = 11))\n```\n\n::: {.cell-output-display}\n![Bias When Excluding an Interaction Effect with the Interaction Effect Varying](index_files/figure-html/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\nWell now we have something that is totally different! For both biased models (excluding $Z$ and excluding $Z$ interacted with $X$), the degree to which they increase with bias increases at about the same rate as the confounder effect / exposure effect ratio increases. However, they are separated basically by their starting point on the y-axis. That's interesting!\n\nAnother interesting key point of difference here is the amount of variability that happens as the x-axis increases. The bias really bunches together when the confounder effect is about 0.1-0.5x the size of the exposure effect, but noticeably increases as the confounder effect approaches the exposure effect before all mayhem breaks out. I also find this very interesting!\n\nAs a final point though, it's important to take a look at the y-axis though and realize that the magnitude of bias in this scenario is really not all that great (hence the -1, 1 y-axis range). But, this range is probably more indicative of the interaction effects I specified rather than some property of omitting interaction effects in general.\n\n# Conclusion\n\nSo, what can you take away from this blog? Well, for the most part, *again, within the context of this simulation exercise*, while getting the functional form specified correctly is important, the bias of excluding a confounder outright seems to have a *way* larger consequence. Which is not surprising at all. However, the final analysis of interaction effects kind of shows that this might not always be true... there were cases when excluding the confounder exhibited less bias than including the confounder without its interaction effect. I wonder if there's something to that or if its just a relic of my simulation exercise or some sort of oversight on my end...\n\nAnd this leads to the ultimate caveat of this blog. This blog was purely exploratory for me. I found writing this fun, but not definitive. So please keep that in mind!\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}