[
  {
    "objectID": "blog/Causal Inference/Causal Inference Blog 1/index.html",
    "href": "blog/Causal Inference/Causal Inference Blog 1/index.html",
    "title": "Causal Inference for Casuals, Part I",
    "section": "",
    "text": "The Promise and Pitfalls of the RCT\nThere is an alternative, however. And this alternative is a big reason for why we probably can trust science when it comes to crucial information like whether a certain medication works. The randomized controlled trial (RCT) is oftentimes viewed as the “gold standard” of scientific research. Given what I explained earlier, you may be shocked to learn that RCTs, when executed correctly, can move beyond correlation and establish causality.\nHow? What about the constant threat of the infamous unobserved confounder? Let’s set the stage to understand how this works. Let’s pretend that you and I are researchers setting out to understand if a certain drug, Drug X (the treatment), causes an increase in muscle mass (the outcome). We can do two things. For one, we can ignore the FDA and release this drug to the public and track information on who buys the drug, individuals who do not buy the drug, and their subsequent muscle masses after taking/not taking the drug. We can then observe that users of Drug X had higher muscle growth than those who did not take Drug X. Causal effect, right? Nope. Let’s draw another DAG (a directed acyclic graph… you saw one earlier and we will go into much greater detail in following blog posts) and quickly point out some confounders\n\n\nCode\ndag2 <- dagify(muscle ~ drugx + age + s_train,\n              drugx ~ age + s_train,\n              s_train ~ age,\n              exposure = \"drugx\",\n              outcome = \"muscle\",\n              coords = list(x = c(muscle = 5, drugx = 1, age = 3, \n                                  s_train = 3),\n                            y = c(muscle = 3, drugx = 3, age = 1, \n                                  s_train = 5)),\n              labels = c(muscle = \"Muscle Mass\",\n                         drugx = \"Drug X\",\n                         age = \"Age\",\n                         s_train = \"Strengh Training\"))\n\ntidy_dag2 <- dag2 %>%\n  tidy_dagitty() %>%\n  node_status()\n\nggplot(tidy_dag2, aes(x = x, y = y, xend = xend, yend = yend)) + \n  theme_dag() +\n  geom_dag_edges() +\n  geom_dag_point(aes(color = status)) +\n  geom_dag_label_repel(aes(label = label, fill = status),\n                       color = \"white\", fontface = \"bold\") +\n  guides(color = \"none\", fill = \"none\")\n\n\n\n\n\nIf we let anyone choose whether they would like to take Drug X, we are introducing all sorts of problems. I noted two of these problems in the DAG, but you can probably think of more. First, individuals who are already committed to muscle mass through a strength training routine will likely have higher muscle mass and may be more willing to take a novel muscle-growth drug. Second, younger people are more likely to engage in a strength training routine and may be more willing to consume a novel drug due to a lack of prior medications and potential complications with mixing prior medication and Drug X. With just two confounders outlined, we are back to Step 1, again.\nAnd this is why we prefer the second option, the RCT. It turns out that if we don’t let people choose if they are receiving treatment, we magically (poof) eliminate confounding effects. We still need voluntary participants, however, so let’s say we recruit 1,200 individuals to participate in our study. Following this, we randomly assign who gets Drug X and who gets the placebo (these individuals serve as the control group who do not get treatment). It is important to not overlook what just happened in this sentence. If we randomly assign who gets access to the treatment, then no other variable can be correlated with treatment. Older and younger people will be equally represented in the treated and control groups because what determined their status as treated or control came down to the equivalent of a coin flip. For the same reason, strength trainers and couch potatoes will be equally represented in the treated and control groups. Theoretically, any confounder (known or unknown) will have equal representation in the treated and control groups. In the updated DAG below, here is what we’ve done with randomization:\n\n\nCode\ndag3 <- dagify(muscle ~ drugx + age + s_train,\n              drugx ~ chance,\n              s_train ~ age,\n              exposure = \"drugx\",\n              outcome = \"muscle\",\n              coords = list(x = c(muscle = 5, drugx = 1, age = 3, \n                                  s_train = 3, chance = 1),\n                            y = c(muscle = 3, drugx = 3, age = 1, \n                                  s_train = 5, chance = 5)),\n              labels = c(muscle = \"Muscle Mass\",\n                         drugx = \"Drug X\",\n                         age = \"Age\",\n                         s_train = \"Strengh Training\",\n                         chance = \"Random Chance\"))\n\ntidy_dag3 <- dag3 %>%\n  tidy_dagitty() %>%\n  node_status()\n\nggplot(tidy_dag3, aes(x = x, y = y, xend = xend, yend = yend)) + \n  theme_dag() +\n  geom_dag_edges() +\n  geom_dag_point(aes(color = status)) +\n  geom_dag_label_repel(aes(label = label, fill = status),\n                       color = \"white\", fontface = \"bold\") +\n  guides(color = \"none\", fill = \"none\")\n\n\n\n\n\nBy definition, nothing is correlated with chance since… it’s chance. Remember that confounders need to be causally linked to treatment and outcome. We got rid of the causal link to treatment part, so we have successfully eliminated all confounding effects. While impressive, the RCT has a very noticeable drawback. It is very difficult to implement. Not all research questions are those where it is feasible or ethical to conduct an RCT. Let’s take my personal research interest as an example, the study of conflict management. Many scholars and policymakers have argued that foreign aid, for example, is a positive force to assist countries recovering from war. Think about whether we could use an RCT here. On the practicality front, the answer is no. No government is going to allow me to randomly assign billion-dollar foreign aid packages to various countries. Now let’s consider the ethical problem. Even if governments would allow me to do so, it is hardly ethical to randomly assign potentially life-saving aid. At best, in these situations and many others, researchers merely observe who gets access to treatment (with observational data) rather than assigning who gets treatment (with experimental data).\n\n\nThe Causal Revolution\nBarring an ability to assign treatment, it seems that we’re back to Step 1 again. Time to settle for correlation when all we have is observational data? Many scholars have, and continue to do so, at this point. Lucky for most researchers, a surprisingly under-the-radar movement and set of scientific contributions known as the “Causal Revolution” has been brewing over the past couple of decades and its insights and capacities are starting to become widely known in academia and data science.\nI won’t get too much into the weeds in this blog post concerning the innovations of the Causal Revolution (there are many), but I would summarize the contributions of the Causal Revolution for causal inference with observational data into four topics. Those nifty DAGs I have shown throughout this blog are extremely valuable for visualizing and specifying confounding (and other) effects. As the research question grows in complexity, so does the DAG and it is very helpful to use DAGs to isolate a variety of causal effects. Second, the Causal Revolution has supplied researchers with an entire causal language that was previously unspoken. As these blog posts continue, you will see all sorts of examples of this new lexicon including: confounders, mediators, colliders, direct effects, indirect effects, various treatment effects, etc. Third, a variety of methods have been developed and refined to estimate causal effects (of which a large portion of blog posts in this series will be concerned with). Lastly, scholars have developed and implemented a crucial type of analysis called “sensitivity analysis” that evaluates the impact of those pesky potentially potentially unobserved confounders (again, we will talk about this in later blog posts).\nAt the very beginning of this series, it is hard to emphasize the monumental importance of these innovations. I think a helpful way of understanding the impact of the Causal Revolution is to compare the state of scientific output now compared to what it was twenty years ago. Two decades ago, language of “causality”, “causal effects”, and even the word “cause” were shunned in many domains where RCTs were not an option. Even when I started graduate school in 2018, the same norm persisted in my department. No language or methods existed to support the leap from correlation to causation. Scholars relied on correlations as a way of assessing the impact of their findings, going right up to the line of interpreting their correlative findings as causal, despite no methods existing to support that leap. Twenty years later, an abundance of methods and innovations support scholars who are now answering questions that researchers, policymakers, and the average individual are interested in. For many areas of study, science is finally capable of answering the questions we have been interested in all along.\n\n\nPotential Outcomes\nOkay, really quick (but very important) side note here. Have you noticed that I haven’t really discussed what causality is or how to evaluate it? We all have a general understanding of causality (if I throw a ball, that movement will cause the ball to move in the direction I threw it), but if we’re going to be all science-y and specific about it, we should consider what we’re actually talking about when we causation.\nJudea Pearl, an instrumental figure (probably the instrumental figure) in the Causal Revolution blatantly avoided precisely defining causality in his fairly-laymen-friendly book, “The Book of Why”. If he avoided providing a precise definition, then who am I to fill in that gap? Rather than giving you a specific definition, I think a general framework is more fruitful for comprehending what causality implies.\nWhether we realize it or not, humans tend to think about causality in terms of counterfactuals (things that didn’t happen, but could have). Think about it. If you get pulled over by a cop for speeding, you understand that, in an alternative world where you were not speeding on that specific highway on that specific day, you probably would not have been pulled over. So, you understand that speeding has a causal effect on the risk of being pulled over by the police. You understand this because you contrast the real world with a counterfactual world where everything else was the same, but you were not speeding. It’s actually that simple. The causal effect of speeding on being pulled over is merely the difference between the real world in which you sped contrasted with the alternative world in which you were not speeding. Any time I mention a causal effect, it is very helpful to think about what that means in this potential outcomes framework.\nYou might be wondering, “that concept makes sense theoretically, but it is practically impossible.” This is correct. We cannot simulate the exact same day for you where the only difference is that you do not speed and compare that to the real world where you have to deal with a speeding ticket. This realization is known as “the fundamental problem of causal inference”. If we had time machines, this wouldn’t be a problem at all. We just go back in time and tell you not to speed on the day where you were pulled over in the original timeline. But we don’t have time machines. So why care about this framework? Is causal inference even possible? Yes, it is. And we will touch up on this issue and how researchers overcome it in later blog posts discussing treatment effects.\nIn the following blog post, we will take a deeper look into directed acyclic graphs (DAGs), beginning with why they have such a complicated name despite being an incredibly intuitive tool. We will look at their effectiveness in identifying a variety of effects (and discuss why identifying these respective effects is important), review the concept of adjustment, and discuss how you can create your own DAGs in R. Before we collect any data or implement a particular method, it is important to understand that causal inference starts with setting aside time to carefully consider causal relationships within a research question. This is why understanding DAGs and visualizing relationships is so important. If we fail to get this part right, then we cannot assign much confidence to the following steps.\n\n\nRecommended Materials\nFor those of you reading this who have a legitimate interest in causal inference and want to know more, I could not recommend the resources below more:\n\nProgram Evaluation Course Provided by Dr. Andrew Heiss: I am putting this at the top of the list for a reason. Dr. Heiss’s course is comprehensive, easy to digest for those who do not come from a strong technical background, and aesthetically pleasing. While it may take some time, I highly suggest taking this entire course. Dr. Heiss also has a lot of valuable information on his blog and GitHUb.\nThe Effect: A fantastic and comprehensive book that covers so much and is so beginner-friendly. As an added plus, this book also provides code for the implementation of methods via R, Python, and Stata. (Plus its free).\nCausal Inference: The Mixtape: Another great book that provides very heplful beginner information relating to causal inference. (Also free).\nRohrer (2018): Reading this article was my first time being exposed to DAGs and the issue of confounding. It is incredibly concise and easy to understand and it is an easy starting point."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Topics on Causal Inference and Data Science",
    "section": "",
    "text": "What Is Causal Inference and Why Does It Matter?\n\n\n\n\ncausal inference\n\n\nDAGs\n\n\npotential outcomes\n\n\n\n\nAn introduction to the world of causal inference for the casual, curious reader.\n\n\n\n\n\n\nFeb 11, 2023\n\n\nBrian Lookabaugh\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nSQL\n\n\ndplyr\n\n\n\n\nA brief introduction/refresher to executing SQL in R and translating between SQL and dplyr syntax.\n\n\n\n\n\n\nFeb 1, 2023\n\n\nBrian Lookabaugh\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/R/SQL and R/index.html",
    "href": "blog/R/SQL and R/index.html",
    "title": "Executing SQL in R",
    "section": "",
    "text": "To begin, we will load the packages that will be utilized in this blog.\n\n\nCode\npacman::p_load(\n  \"dplyr\", ## Data Manipulation in R\n  \"sqldf\", ## Running SQL Queries in R\n  \"dbplyr\", ## Translating dplyr Syntax to SQL Syntax\n  \"DBI\", ## Connecting to a Database\n  \"odbc\", ## Connecting to a Database\n  \"tidyquery\", ## Translating SQL Syntax to dplyr Syntax\n  install = FALSE\n)\n\n\n\nSetting Up Databases\nIn practice, executing SQL in R requires connection to a pre-existing SQL database. For the purpose of this blog, however, we will just be using a temporary database stored in a local RStudio session. We will store this database as an object call con.\n\n\nCode\ncon <- DBI::dbConnect(RSQLite::SQLite(), \":memory:\")\n\n\nFor practical reasons, the syntax above will not be sufficient. Each connection will look different, dependent on various circumstances (the type of relational database management system (RDBMS) being used, log-in information, etc.), so the following example is just that; an example using completely made-up information. However, it does serve as a template for real information to be plugged into.\n\n\nCode\ncon <- dbConnect(odbc(),\n                 Driver = ,\n                 Server = ,\n                 Database = ,\n                 UID = ,\n                 PWD = ,\n                 Port = )\n\n\nReturning to the database we created, it is empty and has no data stored in it. To keep things simple, we are going to load the mtcars data set. We first begin by loading the data into RStudio. The second line of code copies this data set into the local database that we created. Now that we have copied this data into the local database, we can remove the mtcars data set from the local environment.\n\n\nCode\ndata(\"mtcars\")\n\ndbWriteTable(conn = con,\n             name = \"mtcars\",\n             value = mtcars)\n\nrm(mtcars)\n\n\n\n\nRunning a SQL Query in R\nNow that we have the mtcars data in our database, we can run a SQL query to retrieve information from this data. Using the dbGetQuery command, we can execute SQL syntax to return desired information. Here, we are writing a query to return a table which tells us the average miles per gallon for automatic vehicles grouped by the number of cylinders the vehicle has and ordered by miles per gallon from the highest to lowest values.\n\n\nCode\nquery_1 <- dbGetQuery(con,\n  'SELECT ROUND(AVG(mpg)) as avg_mpg, cyl\n   FROM mtcars\n   WHERE am = 1\n   GROUP BY cyl\n   ORDER BY avg_mpg DESC;'\n)\n\ntibble(query_1)\n\n\n# A tibble: 3 × 2\n  avg_mpg   cyl\n    <dbl> <dbl>\n1      28     4\n2      21     6\n3      15     8\n\n\nIn contrast, if you wanted to execute a query on a data frame object instead of pulling from a database, you can use sqldf.\n\n\nCode\nquery_2 <- sqldf(\n  'SELECT ROUND(AVG(mpg)) as avg_mpg, cyl\n   FROM mtcars\n   WHERE am = 1\n   GROUP BY cyl\n   ORDER BY avg_mpg DESC;'\n)\n\ntibble(query_2)\n\n\n# A tibble: 3 × 2\n  avg_mpg   cyl\n    <dbl> <dbl>\n1      28     4\n2      21     6\n3      15     8\n\n\n\n\nRunning a SQL Chunk in RMarkdown/Quarto\nWe can conveniently execute a SQL query in R without relying on a specific command like dbGetQuery. Using RMarkdown or Quarto, we can specify a SQL code chunk. Within the code chunk, you will need to specify the connection (con in our case) and, optionally, the object that the results of the query will be stored in. In the output below, you would begin the code chunk with {sql, connection = con, output.var = \"query_2\"}.\n\n\nCode\nSELECT\n  ROUND(AVG(mpg)) AS avg_mpg,\n  cyl\nFROM mtcars\nWHERE am = 1\nGROUP BY cyl\nORDER BY avg_mpg DESC;\n\n\nNote that if you are going to be using SQL chunks frequently, it is worth specifying the default connection for SQL chunks as demonstrated below.\n\n\nCode\nknitr::opts_chunk$set(connection = \"con\")\n\n\n\n\nTranslating dplyr Syntax to SQL Syntax and Vice Versa\nAnother very helpful tool that bridges the gap between SQL and dplyr syntax is the show_query command. Personally, I found this tool incredibly valuable when learning SQL because of my background in R. Essentially, what this tool does is translate dplyr syntax into SQL syntax. In the opposite direction, through the tidyquery package, we also have the capability to the exact opposite and translate SQL syntax into dplyr syntax. Below demonstrates the functionality of these two commands for the same query. First, translating dplyr syntax to SQL syntax:\n\n\nCode\ntbl(con, \"mtcars\") %>%\n  filter(am == 1) %>%\n  group_by(cyl) %>%\n  summarise(avg_mpg = round(mean(mpg))) %>%\n  ungroup() %>%\n  arrange(dplyr::desc(avg_mpg)) %>%\n  show_query()\n\n\n<SQL>\nSELECT `cyl`, ROUND(AVG(`mpg`), 0) AS `avg_mpg`\nFROM `mtcars`\nWHERE (`am` = 1.0)\nGROUP BY `cyl`\nORDER BY `avg_mpg` DESC\n\n\nNow, we will do the opposite\n\n\nCode\nshow_dplyr(\n  \"SELECT\n    ROUND(AVG(mpg)) AS avg_mpg,\n    cyl\n   FROM mtcars\n   WHERE am = 1\n   GROUP BY cyl\n   ORDER BY avg_mpg DESC;\"\n)\n\n\nmtcars %>%\n  filter(am == 1) %>%\n  group_by(cyl) %>%\n  summarise(avg_mpg = round(mean(mpg, na.rm = TRUE))) %>%\n  ungroup() %>%\n  arrange(dplyr::desc(avg_mpg))\n\n\nObviously, as one’s knowledge in both SQL and R increases, the further capabilities of executing SQL in R can be explored. My hope is that this serves as a helpful introductory for those seeking to integrate data science tools together."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brian Lookabaugh",
    "section": "",
    "text": "My current work is focused on making causal inferences from conflict management programs. Cutting out the jargon, I am curious if policies such as peacekeeping operations, peace agreements, mediation, foreign aid, and foreign direct investment actually contribute to resolving civil conflicts and creating peaceful post-conflict environments. Detailed explanations and technical information concerning this research can be located on the projects section of this site or my Github profile. In addition, I occasionally write blog posts where I primarily discuss topics related to causal inference and data science. In particular, I am working on a comprehensive set of blog posts designed to introduce curious social scientists to causal inference and experimental/quasi-experimental design."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Causal Inference and Data Science Projects",
    "section": "",
    "text": "causal inference\n\n\nquasi-experimental design\n\n\nmatching\n\n\nIPW\n\n\npanel data\n\n\nsensitivity analysis\n\n\n\n\nEmploying a quasi-experimental design, this project estimates the causal impact of UN peacekeeping operation deployments and withdrawals on economic development.\n\n\n\n\n\n\nFeb 4, 2023\n\n\nBrian Lookabaugh\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/UN PKOs and Development/index.html",
    "href": "projects/UN PKOs and Development/index.html",
    "title": "Do UN Peacekeeping Operations Contribute to Economic Development?",
    "section": "",
    "text": "(The entirety of code for this project along with manuscripts, data, and graphics can be found in this GitHub repository).\nObjective: Estimate the causal impact of United Nations (UN) peacekeeping operations (PKOs) on economic development (1994-2007). Theoretically, UN PKO deployments should cause an increase in host economies considering that PKOs provide stability, job opportunities, and an external source of demand for goods and services. Likewise, when PKOs withdraw, stability, PKO-provided job opportunities, and PKO-sourced demand for goods and services may go away, causing a negative effect on host economies. Despite this rationale, prior research suggests unclear results on the impact that UN PKOs have on host country economies.\nMethods: Matching techniques are incredibly popular for causal inference given their simplicity and transparency. However, matching in its canonical setting is designed for cross-sectional research. In many applications, including this project, traditional matching methods are not appropriate. Instead, I use Nearest-neighbor matching and inverse probability weighting using a matching strategy designed for panel data (Imai, Kim, and Wang 2021).\nResults: PKO deployments cause a noticeable decrease in economic development in the eight years following a deployment. For PKO withdrawals, the effect is not statistically significant, but the sign of the effect is increasingly negative over time. However, spillover effects, a lack of spatial and temporal coverage, and the sensitivity of results to unknown confounders places a large asterisks next to these findings."
  },
  {
    "objectID": "projects/UN PKOs and Development/index.html#method",
    "href": "projects/UN PKOs and Development/index.html#method",
    "title": "Do UN Peacekeeping Operations Contribute to Economic Development?",
    "section": "Method",
    "text": "Method\nIn the canonical setting, matching methods are applied to evaluate a situation with a single treatment for various cross-sectional units at a given time. However, applying conventional matching techniques for settings when this is not the case introduces several complications. Within panel data, cross-sectional units can receive multiple treatments over time, units can reverse their treatment status over time, and the treatment itself can be applied at different time intervals for different cross-sectional units. To allow for matching given these possibilities, (Imai, Kim, and Wang 2021) introduced a novel matching method that allows for matching analysis to be executed using panel data. Instead of a unit-time observation being matched with another similar unit-time observation, control observations are selected based on an identical pre-treatment history for a specified timespan (a matched set). For example, if a researcher specified a four-period lag, units would only be matched if their pre-treatment history is identical four-periods prior to treatment. Following this, a refinement method is applied that balances the covariates. For robustness purposes, I use nearest-neighbor matching with Mahalanobis distance and inverse probability weighting (IPW). I conduct two separate analyses for the nearest-neighbor matching, allowing up to 5 matches in one set of analysis and up to 10 matches in the other. Finally, a difference-in-differences (DID) estimator is applied to account for possible time trends in the estimation of the treatment effect3. The causal estimate of interest is a contemporaneous and user-specified lead effect (eight post-treatment years in this analysis) as developed by the model. This is particularly helpful given that there are reasons to suspect that UN PKO deployments and withdrawals create economic effects beyond the immediate time of their deployment/withdrawal."
  },
  {
    "objectID": "projects/UN PKOs and Development/index.html#range-of-cases",
    "href": "projects/UN PKOs and Development/index.html#range-of-cases",
    "title": "Do UN Peacekeeping Operations Contribute to Economic Development?",
    "section": "Range of Cases",
    "text": "Range of Cases\nThe range of cases available in this study are all civil war and post-civil war cases as identified by the Uppsala Conflict Data Program (UCDP)/International Peace Research Institute in Oslo (PRIO) Armed Conflict Dataset, ranging from 1994 to 2007 (Gleditsch et al. 2002; Davies, Pettersson, and Öberg 2022). To qualify as a conflict-state, a country must experience at least 25 battle-related deaths per year. A post-conflict state is subsequently any state that has experienced conflict prior and whose battle-related death count has fallen below the threshold. At any point, a post-conflict state may experience conflict recurrence, in which the 25-deaths threshold is crossed. These observations remain the data set, as they are both conflict and post-conflict cases. To avoid artificial cases of civil war caused by bloody military coups that result in at least 25 deaths, I recode instances of military coups as “non-civil war”. Criteria for coups is acquired from Powell and Thyne (2011). Finally, temporary lulls in conflict may result in the battle deaths threshold dropping below 25 despite conflict remaining ongoing. A consequence of leaving this unaddressed is an incorrectly inflated number of short post-conflict “peace” spells that actually represent short-term lulls in conflict intensity. To correct for this, I recode three-year (or less) spells of “peace” as conflict-level cases."
  },
  {
    "objectID": "projects/UN PKOs and Development/index.html#variables",
    "href": "projects/UN PKOs and Development/index.html#variables",
    "title": "Do UN Peacekeeping Operations Contribute to Economic Development?",
    "section": "Variables",
    "text": "Variables\nBecause this study seeks to estimate the causal impact of UN PKOs on economic development, I follow standard convention and measure economic development as GDP per capita (log-transformed). Data on GDP per capita is acquired from Fariss, Therese, and Miriam (2022) who employ latent variable modeling to account for missing data, a particularly useful feature of their data collection strategy for the purpose of this paper given the already comparatively small N. 4\nInformation on the location of UN peacekeeping operations is acquired from the Geocoded Peacekeeping Operations (Geo-PKO) Dataset v. 2.0 (Cil et al. 2020) which covers UN PKOs from 1994-2020. The Geo-PKO Dataset is aggregated at the sub-national level. However, I aggregate this data at the country-year level to account for confounding effects where data is aggregated at the country-year level. UN PKOs are operationalized as a dummy where a value of “1” denotes a country-year where a UN PKO is present and a value of “0” denotes a country-year where a UN PKO is not present.\nA number of confounding factors complicate the causal relationship between PKOs and development. To isolate a causal effect, it is necessary to account for these confounding factors. First, many authors have argued that the UN has a general aversion to entering armed combat with military forces of the state (Gilligan and Stedman 2003; Fjelde, Hultman, and Nilsson 2018). Likewise, states with stronger military capacity may be able to enforce a greater degree of order over the territories they control, impacting the prospects of order and stability. Such order and stability may be more conducive to economic growth and development. To account for this confounding effect, government capacity is measured as the log-transformed number of military personnel per capita acquired from the Correlates of War National Military Capabilities data set v.5.0 (Singer, Bremer, and Stuckey 1972; Singer 1987). Second, the duration of conflict also effects both the presence of a PKO and prospects for economic development. As the duration of a war increases, the authorization of a PKO may likewise increase as the need for international intervention may be viewed as necessary to terminate conflict. Additionally, the longer war continues, the farther away the process of post-conflict economic recovery is pushed. I measure war duration using the count of years a conflict (as defined by UCDP) has been ongoing. If a conflict is not ongoing, war duration is simply coded as “0”. Third, the size of a potential target country’s population may also influence the likelihood of development and receiving a UN PKO. Many scholars have argued that a connection exists between population growth and economic growth (Headey and Hodge 2009; Prettner and Prskawetz 2010; Peterson 2017). In addition, if the UN is concerned with its post-intervention success, smaller countries may represent a more tempting target as they might be easier to manage and govern. A log-transformed population variable is therefore introduced to account for this confounding effect. Fourth, levels of conflict intensity may impact prospects for development and the chances of a UN PKO being authorized. To measure conflict intensity, I use a log-transformed value of the count of all battle-related and one-sided violence-related deaths. Data on conflict intensity is acquired from UCDP’s Georeferenced Events Dataset (Davies, Pettersson, and Öberg 2022; Sundberg and Melander 2013). Lastly, I use the Variety of Democracy’s (V-Dem) “electoral democracy index” to account for the effect that democracy may have on economic development (Teorell et al. 2019; Coppedge et al. 2022). While the theoretical logic linking democracy to development has not been firmly settled, the empirical linkage between the two is well-established (Barro 1996; Acemoglu et al. 2019). Given that there is not much extant research suggesting that UN PKOs should be more likely to intervene in democratic cases, I do not consider democracy to be a confounding factor. Nonetheless, including variables that affect the outcome but not the treatment (“neutral” controls) may decrease the variation in the outcome and improve the precision of estimates."
  },
  {
    "objectID": "projects/UN PKOs and Development/index.html#sensitivity-analysis",
    "href": "projects/UN PKOs and Development/index.html#sensitivity-analysis",
    "title": "Do UN Peacekeeping Operations Contribute to Economic Development?",
    "section": "Sensitivity Analysis",
    "text": "Sensitivity Analysis\nInitially, this short list of confounders may seem inefficient to capture all confounding effects complicating the relationship between PKOs and development. Fortunately, we do not have to blindly wonder if an estimated causal effect from observational data is legitimate or if it is biased by an unspecified confounder. Sensitivity analysis can be employed to quantitatively assess the extent to which unobserved confounding may bias observed results. While the variety of sensitivity analyses is large, I follow the approach of Cinelli and Hazlett (2020). In this approach, a researcher specifies a benchmark covariate. This covariate should be one that is observed in the model and one the researcher believes should have the largest substantive effect among the group of observed covariates. Hypothetical unobserved confounders are then constructed with varying levels of strength relative to the specified benchmark covariate (one times as large as the benchmark covariate, twice as large, three times as large, etc.). Following this, researchers are able to both numerically and graphically assess the extent to which an unobserved confounder of varying strengths has the capacity to reduce or flip a causal estimate. Unfortunately, this method is not directly applicable for matching with panel data. Given the novelty of the panel data matching approach, this is not surprising. Instead of estimating the sensitivity of the estimates generated from the panel data matching analysis, I utilize sensitivity analysis to demonstrate the sensitivity of an estimate using a standard linear regression model with statistical control to account for covariates. While this approach is not applicable for the results of the panel data matching analysis, it is insightful for quantitatively assessing the sensitivity of coefficients using the predominant approach in the literature to estimate effect sizes and directions.\n\n\nCode\npacman::p_load(\n  \"tidyverse\", # Data Manipulation and Visualization\n  \"DescTools\", # Last Observation Carried Forward (LOCF) Command\n  install = FALSE\n)\n\n# Create the Base Data Set to Identify The Presence of Civil War and Post-Civil War\nucdp <- readr::read_csv(\"Data/ucdp-prio-acd-221.csv\")\n\nucdp <- ucdp %>%\n  mutate(gwno_a = as.numeric(gwno_a)) %>%\n  filter(type_of_conflict == 3) %>% # Filter Cases of Civil Conflict\n  mutate(civ_war = 1) %>% # Set Civil War Equal to 1 for Civil War Cases\n  group_by(gwno_a, year) %>% # Collapse This Data to the Country-Year Level\n  summarise(civ_war = max(civ_war)) %>%\n  ungroup()\n\n# Merge This Data With COW States Data to Identify All Country-Years\ncow <- readr::read_csv(\"Data/system2016_cow.csv\")\n\nucdp <- left_join(cow, ucdp,\n                  by = c(\"ccode\" = \"gwno_a\", \"year\"))\n\n\n# Make Coups Count As Non-Civil War Observations\n# Coup Information (Powell and Thyme 2011) Along With Confounders\nvdem <- readr::read_csv(\"Data/selected_vdem_v12.csv\") \n\nucdp <- left_join(ucdp, vdem,\n                  by = c(\"ccode\" = \"COWcode\", \"year\"))\n\nucdp <- ucdp %>%\n  mutate(coup = if_else(\n    e_pt_coup > 0, 1, e_pt_coup\n  )) %>%\n  mutate(civ_war = if_else( # Re-Code Civil Wars As Not Cases of Civil War Where Coups Occurred\n    coup == 1, 0, civ_war\n  )) %>%\n  select(-c(e_pt_coup, coup))\n\n# Re-Code 3 Years or Less of Peace As Conflict Lulls\nucdp <- ucdp %>%\n  group_by(ccode) %>%\n  mutate(flag_civ_war = lag(civ_war, n = 1, order_by = ccode)) %>%\n  mutate(flead_civ_war = lead(civ_war, n = 1, order_by = ccode)) %>%\n  mutate(slag_civ_war = lag(civ_war, n = 2, order_by = ccode)) %>%\n  mutate(slead_civ_war = lead(civ_war, n = 2, order_by = ccode)) %>%\n  ungroup() %>%\n  mutate(civ_war = if_else(\n    flag_civ_war == 1 & flead_civ_war == 1, 1, civ_war\n  )) %>%\n  mutate(civ_war = if_else(\n    slag_civ_war == 1 & slead_civ_war == 1, 1, civ_war\n  )) %>%\n  select(-c(flag_civ_war, flead_civ_war, slag_civ_war, slead_civ_war))\n\n# Create an \"Ever Civil War\" Variable to Isolate Post-Conflict Cases  \nucdp <- ucdp %>%\n  arrange(ccode, year) %>%\n  group_by(ccode) %>%\n  mutate(ev_civwar = LOCF(civ_war)) %>%\n  ungroup() %>%\n  mutate(ev_civwar = if_else(\n    is.na(ev_civwar), 0, ev_civwar\n  ))\n\n# Replace NA Values for Civil War and Ever Civil War With 0\nucdp <- ucdp %>%\n  mutate(civ_war = if_else(\n    is.na(civ_war), 0, civ_war\n  ))\n\n# Create Spell ID Variable\nucdp <- ucdp %>%\n  group_by(ccode) %>%\n  mutate(con_fail = if_else( # Start By Creating a Conflict/Peace Termination (Failure) Variable\n    lag(civ_war == 1) & civ_war == 0, 1, 0\n  )) %>%\n  mutate(peace_fail = if_else( \n    lag(civ_war == 0) & civ_war == 1, 1, 0\n  )) %>%\n  ungroup() %>%\n  mutate(id = cumsum(peace_fail)) # The Actual ID (This Includes Non-Conflict Cases)\n\n# Filter Non-Conflict Cases\nucdp <- ucdp %>%\n  filter(ev_civwar > 0)\n\n# Create the War Duration Variable\nucdp <- ucdp %>%\n  group_by(id) %>%\n  mutate(wardur = as.numeric(row_number())) %>% # Default Is Integer\n  ungroup() %>%\n  mutate(wardur = if_else( # Replace Peace-Year Values With 0\n    civ_war == 0, 0, wardur\n  ))\n\n# Manipulate and Merge GED Data\nload(\"Data/ucdp_ged_22_1.RData\")\nged <- GEDEvent_v22_1\nrm(GEDEvent_v22_1)\n\nged <- ged %>%\n  mutate(gwnoa = as.numeric(gwnoa)) %>%\n  group_by(gwnoa, year) %>%\n  summarise(deaths = max(best)) %>%\n  ungroup()\n\nucdp <- left_join(ucdp, ged,\n                 by = c(\"ccode\" = \"gwnoa\", \"year\"))\n\nucdp <- ucdp %>% # Replace NA Values With 0\n  mutate(deaths = as.numeric(deaths)) %>%\n  mutate(deaths = if_else(\n    is.na(deaths), 0, deaths\n  ))\n\n# Merge the Geo-PKO Data\ngeo_pko <- readr::read_csv(\"Data/geo_pko_v.2.0.csv\")\n\ngeo_pko <- geo_pko %>%\n  mutate(pko = 1) %>%\n  group_by(cow_code, year) %>%\n  summarise(pko = max(pko)) %>%\n  ungroup()\n\nucdp <- left_join(ucdp, geo_pko,\n                 by = c(\"ccode\" = \"cow_code\", \"year\"))\n\nucdp <- ucdp %>% # Replace NA Values for PKO With 0\n  mutate(pko = if_else(\n    is.na(pko), 0, pko\n  ))\n\n# Load and Clean Correlates of War (COW) Data for Military Capacity\nmilcap <- readr::read_csv(\"Data/cow_nmc_v4.csv\")\n\nmilcap <- milcap %>%\n  filter(milper != -9) %>% # Remove NA Values\n  select(c(ccode, year, milper)) # Keep Selected Columns\n\nucdp <- left_join(ucdp, milcap,\n                 by = c(\"ccode\", \"year\"))\n\n# Generate Log-Transformed Values\nucdp <- ucdp %>%\n  mutate(lgdppc = log(e_gdppc + 1)) %>%\n  mutate(lpop = log(e_pop)) %>%\n  mutate(lmilper = log(milper + 1)) %>%\n  mutate(ldeaths = log(deaths + 1)) %>%\n  rename(democracy = v2x_polyarchy)\n\n# Create PKO Event Variables\nucdp <- ucdp %>%\n  mutate(pko_onset = if_else(\n    lag(pko == 0) & pko == 1, 1, 0\n  )) %>%\n  mutate(pko_term = if_else(\n    lag(pko == 1) & pko == 0, 1, 0\n  )) %>%\n  filter(ccode != 437) # Filter Ivory Coast Since It Has a PKO But No Onset/Termination\n\n# Remove Unnecessary Columns\nmerged <- ucdp %>%\n  select(-c(e_total_fuel_income_pc, e_total_oil_income_pc, e_total_resources_income_pc,\n            ...6, e_pop, e_gdppc, e_wb_pop, e_mipopula, version, con_fail,\n            peace_fail, milper))\n\n# Remove Unnecessary Data Sets\nrm(cow, ged, geo_pko, milcap, vdem, ucdp)"
  },
  {
    "objectID": "projects/UN PKOs and Development/index.html#treatment-variation",
    "href": "projects/UN PKOs and Development/index.html#treatment-variation",
    "title": "Do UN Peacekeeping Operations Contribute to Economic Development?",
    "section": "Treatment Variation",
    "text": "Treatment Variation\nBecause matching methods rely on a comparable control unit for every treated unit, the number of observations naturally shrink when compared to standard regression-based designs. If treatment is a fairly rare event (such as PKO deployments/withdrawals), then N will be, at minimum, twice the size of the number of treated units. If the number of treated units is particularly low, this may be problematic as the subsequent N in such a design would likewise be concerningly low. In addition, if treatment is clustered heavily within a certain timeframe or in a certain area, it may be difficult to generalize results beyond the temporal-spatial clusters. To visually assess such concerns, Figure Figure 1 below visualizes the distribution of treatment across time and space (blank spaces represent country-year observations where the country did not exist).\n\n\nCode\nmerged <- merged %>%\n  mutate(year = as.integer(year))\n\nmerged <- as.data.frame(merged)\n\nmerged <- merged %>% # Drop Observations Pre-1994 and Post-2007 for Plot\n  filter(year >= 1994, year < 2008) \n\nDisplayTreatment(\n  unit.id = \"stateabb\",\n  time.id = \"year\",\n  xlab = \"Year\",\n  ylab = \"Countries\",\n  y.size = 6,\n  title = \"\",\n  legend.position = \"bottom\",\n  legend.labels = c(\"No PKO\", \"PKO\"),\n  hide.x.tick.label = TRUE,\n  treatment = \"pko\",\n  data = merged\n) + \n  theme(axis.text.x = element_text(angle = 0, size = 6.5, vjust = 0.5)) +\n  scale_x_discrete(breaks = c(1995, 2000, 2005))\n\n\n\n\n\nFigure 1: Treatment-Variation Plot\n\n\n\n\nA number of observations can be made from a glance at this plot. First, treatment (PKO) is clustered in time and in space. It is well-known that UN PKOs as they are conceived of today (large deployments of armed personnel to assist in the implementation of peace agreements and to police post-conflict environments) were practically non-existent prior to the end of the Cold War. Further, UN PKOs are heavily clustered in African countries. Given that the debate surrounding PKOs concerns their contemporary effectiveness (rather than a retrospective Cold War-era effectiveness), the temporal clustering of PKOs is a minor issue. However, the clustering of PKOs in African countries is problematic for generalizability given the logic of matching. Recall that in the panel data matching setup, units are matched based on a pre-specified number of years where treatment status is the same and values in covariates are similar. At time t, matched sets are allowed to differ based on their treatment status. Given that most treatments occur in Africa, matched sets will primarily consist of African countries as African countries share many baseline similarities to one another. While this is not an issue if one wishes to evaluate the effectiveness of PKOs in Africa, it is an issue for researchers wishing to make universal claims concerning the effectiveness of PKOs in conflict-stricken areas. Because of this, I proceed with the analysis under the assumption that such results generated from this analysis may not be generalizable beyond the post-Cold War African context."
  },
  {
    "objectID": "projects/UN PKOs and Development/index.html#balance-assessment",
    "href": "projects/UN PKOs and Development/index.html#balance-assessment",
    "title": "Do UN Peacekeeping Operations Contribute to Economic Development?",
    "section": "Balance Assessment",
    "text": "Balance Assessment\nThe virtue of matching techniques over statistical control is derived from the former’s ability to more effectively balance covariates. The goal of refining techniques such as nearest-neighbor matching or inverse probability weighting is to construct a new data set where observations are weighted so that units as similar as possible as it relates to the pre-specified covariates (but different as it relates to treatment status) are compared to one another. However, refinement is not a guarantee that balance has been achieved. Figures Figure 2 and Figure 3 plot the effectiveness of select refinement methods such as nearest-neighbor matching using Mahalanobis distance (up to 5 and 10 matches, respectively) and inverse probability weighting. In particular, Figure Figure 2 assesses covariate balance when PKO deployments are considered as treatment and Figure Figure 3 assesses covariate balance when PKO withdrawals are considered as treatment. The x-axis reflects the standardized mean difference between covariates for the treated and control units prior to the execution of the specified refinement method. The y-axis reflects the standardized mean difference between covariates for the treated and control units following the execution of the specified refinement method. Each dot in the plot reflects a specific covariate. Dots falling below the 45-degree dashed line suggest an improvement in covariate balance post-refinement. Dots falling above the dashed line imply that the select refinement method decreased covariate balance. To reach an ideal level of covariate balance, dots should cluster at the lower end of the y-axis. Balance is assessed at various lag thresholds (one-to-four-year lags) to examine how sensitive balancing is to the criteria established for the generation of matched sets.\n\n\nCode\nmerged <- merged %>%\n  mutate(ccode = as.integer(ccode)) %>%\n  select(-c(stateabb)) # PanelMatch Will Not Run With Non-Numeric/Integer Data\n\n# NN Matching - 5 Matches - 1 Lag\nnn_match_5_1 <- PanelMatch(lag = 1,\n                         time.id = \"year\",\n                         unit.id = \"ccode\",\n                         treatment = \"pko_onset\",\n                         refinement.method = \"mahalanobis\",\n                         size.match = 5,\n                         data = merged,\n                         covs.formula = ~ \n                           I(lag(lpop, 1)) +\n                           I(lag(lmilper, 1)) +\n                           I(lag(ldeaths, 1)) +\n                           I(lag(wardur, 1)) +\n                           I(lag(democracy, 1)),\n                         qoi = \"att\",\n                         outcome.var = \"lgdppc\",\n                         use.diagonal.variance.matrix = TRUE,\n                         restrict.control.period = 1)\n\n# NN Matching - 5 Matches - 2 Lags\nnn_match_5_2 <- PanelMatch(lag = 2,\n                           time.id = \"year\",\n                           unit.id = \"ccode\",\n                           treatment = \"pko_onset\",\n                           refinement.method = \"mahalanobis\",\n                           size.match = 5,\n                           data = merged,\n                           covs.formula = ~ \n                             I(lag(lpop, 1:2)) +\n                             I(lag(lmilper, 1:2)) +\n                             I(lag(ldeaths, 1:2)) +\n                             I(lag(wardur, 1:2)) +\n                             I(lag(democracy, 1:2)),\n                           qoi = \"att\",\n                           outcome.var = \"lgdppc\",\n                           use.diagonal.variance.matrix = TRUE,\n                           restrict.control.period = 2)\n\n# NN Matching - 5 Matches - 3 Lags\nnn_match_5_3 <- PanelMatch(lag = 3,\n                           time.id = \"year\",\n                           unit.id = \"ccode\",\n                           treatment = \"pko_onset\",\n                           refinement.method = \"mahalanobis\",\n                           size.match = 5,\n                           data = merged,\n                           covs.formula = ~ \n                             I(lag(lpop, 1:3)) +\n                             I(lag(lmilper, 1:3)) +\n                             I(lag(ldeaths, 1:3)) +\n                             I(lag(wardur, 1:3)) +\n                             I(lag(democracy, 1:3)),\n                           qoi = \"att\",\n                           outcome.var = \"lgdppc\",\n                           use.diagonal.variance.matrix = TRUE,\n                           restrict.control.period = 3)\n\n# NN Matching - 5 Matches - 4 Lags\nnn_match_5_4 <- PanelMatch(lag = 4,\n                           time.id = \"year\",\n                           unit.id = \"ccode\",\n                           treatment = \"pko_onset\",\n                           refinement.method = \"mahalanobis\",\n                           size.match = 5,\n                           data = merged,\n                           covs.formula = ~ \n                             I(lag(lpop, 1:4)) +\n                             I(lag(lmilper, 1:4)) +\n                             I(lag(ldeaths, 1:4)) +\n                             I(lag(wardur, 1:4)) +\n                             I(lag(democracy, 1:4)),\n                           qoi = \"att\",\n                           outcome.var = \"lgdppc\",\n                           use.diagonal.variance.matrix = TRUE,\n                           restrict.control.period = 4)\n\n# NN Matching - 10 Matches - 1 Lag\nnn_match_10_1 <- PanelMatch(lag = 1,\n                          time.id = \"year\",\n                          unit.id = \"ccode\",\n                          treatment = \"pko_onset\",\n                          refinement.method = \"mahalanobis\",\n                          size.match = 10,\n                          data = merged,\n                          covs.formula = ~ \n                            I(lag(lpop, 1)) +\n                            I(lag(lmilper, 1)) +\n                            I(lag(ldeaths, 1)) +\n                            I(lag(wardur, 1)) +\n                            I(lag(democracy, 1)),\n                          qoi = \"att\",\n                          outcome.var = \"lgdppc\",\n                          use.diagonal.variance.matrix = TRUE,\n                          restrict.control.period = 1)\n\n# NN Matching - 10 Matches - 2 Lags\nnn_match_10_2 <- PanelMatch(lag = 2,\n                            time.id = \"year\",\n                            unit.id = \"ccode\",\n                            treatment = \"pko_onset\",\n                            refinement.method = \"mahalanobis\",\n                            size.match = 10,\n                            data = merged,\n                            covs.formula = ~ \n                              I(lag(lpop, 1:2)) +\n                              I(lag(lmilper, 1:2)) +\n                              I(lag(ldeaths, 1:2)) +\n                              I(lag(wardur, 1:2)) +\n                              I(lag(democracy, 1:2)),\n                            qoi = \"att\",\n                            outcome.var = \"lgdppc\",\n                            use.diagonal.variance.matrix = TRUE,\n                            restrict.control.period = 2)\n\n# NN Matching - 10 Matches - 3 Lags\nnn_match_10_3 <- PanelMatch(lag = 3,\n                            time.id = \"year\",\n                            unit.id = \"ccode\",\n                            treatment = \"pko_onset\",\n                            refinement.method = \"mahalanobis\",\n                            size.match = 10,\n                            data = merged,\n                            covs.formula = ~ \n                              I(lag(lpop, 1:3)) +\n                              I(lag(lmilper, 1:3)) +\n                              I(lag(ldeaths, 1:3)) +\n                              I(lag(wardur, 1:3)) +\n                              I(lag(democracy, 1:3)),\n                            qoi = \"att\",\n                            outcome.var = \"lgdppc\",\n                            use.diagonal.variance.matrix = TRUE,\n                            restrict.control.period = 3)\n\n# NN Matching - 10 Matches - 4 Lags\nnn_match_10_4 <- PanelMatch(lag = 4,\n                            time.id = \"year\",\n                            unit.id = \"ccode\",\n                            treatment = \"pko_onset\",\n                            refinement.method = \"mahalanobis\",\n                            size.match = 10,\n                            data = merged,\n                            covs.formula = ~ \n                              I(lag(lpop, 1:4)) +\n                              I(lag(lmilper, 1:4)) +\n                              I(lag(ldeaths, 1:4)) +\n                              I(lag(wardur, 1:4)) +\n                              I(lag(democracy, 1:4)),\n                            qoi = \"att\",\n                            outcome.var = \"lgdppc\",\n                            use.diagonal.variance.matrix = TRUE,\n                            restrict.control.period = 4)\n\n# IPW - 1 Lag\nipw_1 <- PanelMatch(lag = 1,\n                  time.id = \"year\",\n                  unit.id = \"ccode\",\n                  treatment = \"pko_onset\",\n                  refinement.method = \"ps.weight\",\n                  data = merged,\n                  covs.formula = ~\n                    I(lag(lpop, 1)) +\n                    I(lag(lmilper, 1)) +\n                    I(lag(ldeaths, 1)) +\n                    I(lag(wardur, 1)) +\n                    I(lag(democracy, 1)),\n                  qoi = \"att\",\n                  outcome.var = \"lgdppc\",\n                  restrict.control.period = 1)\n\n# IPW - 2 Lags\nipw_2 <- PanelMatch(lag = 2,\n                  time.id = \"year\",\n                  unit.id = \"ccode\",\n                  treatment = \"pko_onset\",\n                  refinement.method = \"ps.weight\",\n                  data = merged,\n                  covs.formula = ~\n                    I(lag(lpop, 1:2)) +\n                    I(lag(lmilper, 1:2)) +\n                    I(lag(ldeaths, 1:2)) +\n                    I(lag(wardur, 1:2)) +\n                    I(lag(democracy, 1:2)),\n                  qoi = \"att\",\n                  outcome.var = \"lgdppc\",\n                  restrict.control.period = 2)\n\n# IPW - 3 Lags\nipw_3 <- PanelMatch(lag = 3,\n                  time.id = \"year\",\n                  unit.id = \"ccode\",\n                  treatment = \"pko_onset\",\n                  refinement.method = \"ps.weight\",\n                  data = merged,\n                  covs.formula = ~\n                    I(lag(lpop, 1:3)) +\n                    I(lag(lmilper, 1:3)) +\n                    I(lag(ldeaths, 1:3)) +\n                    I(lag(wardur, 1:3)) +\n                    I(lag(democracy, 1:3)),\n                  qoi = \"att\",\n                  outcome.var = \"lgdppc\",\n                  restrict.control.period = 3)\n\n# IPW - 4 Lags\nipw_4 <- PanelMatch(lag = 4,\n                  time.id = \"year\",\n                  unit.id = \"ccode\",\n                  treatment = \"pko_onset\",\n                  refinement.method = \"ps.weight\",\n                  data = merged,\n                  covs.formula = ~\n                    I(lag(lpop, 1:4)) +\n                    I(lag(lmilper, 1:4)) +\n                    I(lag(ldeaths, 1:4)) +\n                    I(lag(wardur, 1:4)) +\n                    I(lag(democracy, 1:4)),\n                  qoi = \"att\",\n                  outcome.var = \"lgdppc\",\n                  restrict.control.period = 4)\n\n# Create the Composite Covariate Balance Plot\nplot.new()\npar(oma = c(5, 10, 1.5, 0),\n    mar = c(0.8, .9, 1.5, 0.45),\n    mfrow = c(3,4),\n    pty = \"s\")\n\nbalance_scatter(\n  nn_match_5_1,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_5_2,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_5_3,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_5_4,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_10_1,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_10_2,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_10_3,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_10_4,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  ipw_1,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\"\n)\n\nbalance_scatter(\n  ipw_2,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  ipw_3,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  ipw_4,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  yaxt = \"n\"\n)\n\nmtext(1,text = \"Standardized Mean Difference \\n Before Refinement\",\n      line = 3.5,\n      at = 0.52, outer = TRUE, cex = 1)\nmtext(2, text = \"Standardized Mean Difference \\n After Refinement\",\n      line = 4, outer = TRUE)\nmtext(2, text = \"NN Matching \\n Up to 5\",\n      line = 1.15, at = .82, outer = TRUE,\n      cex = .8)\nmtext(2, text = \"NN Matching \\n Up to 10\",\n      line = 1.15, at = .5, outer = TRUE,\n      cex = .8)\nmtext(2, text = \"IPW\",\n      line = 1.15, at = .16, outer = TRUE,\n      cex = .8)\nmtext(\"One Year Lag\",\n      line = 0, at = 0.125, outer = TRUE, cex = .8)\nmtext(\"Two Year Lag\",\n      line = 0, at = 0.375, outer = TRUE, cex = .8)\nmtext(\"Three Year Lag\",\n      line = 0, at = 0.625, outer = TRUE, cex = .8)\nmtext(\"Four Year Lag\",\n      line = 0, at = .875, outer = TRUE, cex = .8)\n\n\n\n\n\nFigure 2: Covariate Balance for PKO Deployments As Treatment\n\n\n\n\n\n\nCode\nnn_match_5_1 <- PanelMatch(lag = 1,\n                           time.id = \"year\",\n                           unit.id = \"ccode\",\n                           treatment = \"pko_term\",\n                           refinement.method = \"mahalanobis\",\n                           size.match = 5,\n                           data = merged,\n                           covs.formula = ~ \n                             I(lag(lpop, 1)) +\n                             I(lag(lmilper, 1)) +\n                             I(lag(ldeaths, 1)) +\n                             I(lag(wardur, 1)) +\n                             I(lag(democracy, 1)),\n                           qoi = \"att\",\n                           outcome.var = \"lgdppc\",\n                           use.diagonal.variance.matrix = TRUE,\n                           restrict.control.period = 1)\n\nnn_match_5_2 <- PanelMatch(lag = 2,\n                           time.id = \"year\",\n                           unit.id = \"ccode\",\n                           treatment = \"pko_term\",\n                           refinement.method = \"mahalanobis\",\n                           size.match = 5,\n                           data = merged,\n                           covs.formula = ~ \n                             I(lag(lpop, 1:2)) +\n                             I(lag(lmilper, 1:2)) +\n                             I(lag(ldeaths, 1:2)) +\n                             I(lag(wardur, 1:2)) +\n                             I(lag(democracy, 1:2)),\n                           qoi = \"att\",\n                           outcome.var = \"lgdppc\",\n                           use.diagonal.variance.matrix = TRUE,\n                           restrict.control.period = 2)\n\nnn_match_5_3 <- PanelMatch(lag = 3,\n                           time.id = \"year\",\n                           unit.id = \"ccode\",\n                           treatment = \"pko_term\",\n                           refinement.method = \"mahalanobis\",\n                           size.match = 5,\n                           data = merged,\n                           covs.formula = ~ \n                             I(lag(lpop, 1:3)) +\n                             I(lag(lmilper, 1:3)) +\n                             I(lag(ldeaths, 1:3)) +\n                             I(lag(wardur, 1:3)) +\n                             I(lag(democracy, 1:3)),\n                           qoi = \"att\",\n                           outcome.var = \"lgdppc\",\n                           use.diagonal.variance.matrix = TRUE,\n                           restrict.control.period = 3)\n\nnn_match_5_4 <- PanelMatch(lag = 4,\n                           time.id = \"year\",\n                           unit.id = \"ccode\",\n                           treatment = \"pko_term\",\n                           refinement.method = \"mahalanobis\",\n                           size.match = 5,\n                           data = merged,\n                           covs.formula = ~ \n                             I(lag(lpop, 1:4)) +\n                             I(lag(lmilper, 1:4)) +\n                             I(lag(ldeaths, 1:4)) +\n                             I(lag(wardur, 1:4)) +\n                             I(lag(democracy, 1:4)),\n                           qoi = \"att\",\n                           outcome.var = \"lgdppc\",\n                           use.diagonal.variance.matrix = TRUE,\n                           restrict.control.period = 4)\n\nnn_match_10_1 <- PanelMatch(lag = 1,\n                            time.id = \"year\",\n                            unit.id = \"ccode\",\n                            treatment = \"pko_term\",\n                            refinement.method = \"mahalanobis\",\n                            size.match = 10,\n                            data = merged,\n                            covs.formula = ~ \n                              I(lag(lpop, 1)) +\n                              I(lag(lmilper, 1)) +\n                              I(lag(ldeaths, 1)) +\n                              I(lag(wardur, 1)) +\n                              I(lag(democracy, 1)),\n                            qoi = \"att\",\n                            outcome.var = \"lgdppc\",\n                            use.diagonal.variance.matrix = TRUE,\n                            restrict.control.period = 1)\n\nnn_match_10_2 <- PanelMatch(lag = 2,\n                            time.id = \"year\",\n                            unit.id = \"ccode\",\n                            treatment = \"pko_term\",\n                            refinement.method = \"mahalanobis\",\n                            size.match = 10,\n                            data = merged,\n                            covs.formula = ~ \n                              I(lag(lpop, 1:2)) +\n                              I(lag(lmilper, 1:2)) +\n                              I(lag(ldeaths, 1:2)) +\n                              I(lag(wardur, 1:2)) +\n                              I(lag(democracy, 1:2)),\n                            qoi = \"att\",\n                            outcome.var = \"lgdppc\",\n                            use.diagonal.variance.matrix = TRUE,\n                            restrict.control.period = 2)\n\nnn_match_10_3 <- PanelMatch(lag = 3,\n                            time.id = \"year\",\n                            unit.id = \"ccode\",\n                            treatment = \"pko_term\",\n                            refinement.method = \"mahalanobis\",\n                            size.match = 10,\n                            data = merged,\n                            covs.formula = ~ \n                              I(lag(lpop, 1:3)) +\n                              I(lag(lmilper, 1:3)) +\n                              I(lag(ldeaths, 1:3)) +\n                              I(lag(wardur, 1:3)) +\n                              I(lag(democracy, 1:3)),\n                            qoi = \"att\",\n                            outcome.var = \"lgdppc\",\n                            use.diagonal.variance.matrix = TRUE,\n                            restrict.control.period = 3)\n\nnn_match_10_4 <- PanelMatch(lag = 4,\n                            time.id = \"year\",\n                            unit.id = \"ccode\",\n                            treatment = \"pko_term\",\n                            refinement.method = \"mahalanobis\",\n                            size.match = 10,\n                            data = merged,\n                            covs.formula = ~ \n                              I(lag(lpop, 1:4)) +\n                              I(lag(lmilper, 1:4)) +\n                              I(lag(ldeaths, 1:4)) +\n                              I(lag(wardur, 1:4)) +\n                              I(lag(democracy, 1:4)),\n                            qoi = \"att\",\n                            outcome.var = \"lgdppc\",\n                            use.diagonal.variance.matrix = TRUE,\n                            restrict.control.period = 4)\n\nipw_1 <- PanelMatch(lag = 1,\n                    time.id = \"year\",\n                    unit.id = \"ccode\",\n                    treatment = \"pko_term\",\n                    refinement.method = \"ps.weight\",\n                    data = merged,\n                    covs.formula = ~\n                      I(lag(lpop, 1)) +\n                      I(lag(lmilper, 1)) +\n                      I(lag(ldeaths, 1)) +\n                      I(lag(wardur, 1)) +\n                      I(lag(democracy, 1)),\n                    qoi = \"att\",\n                    outcome.var = \"lgdppc\",\n                    restrict.control.period = 1)\n\nipw_2 <- PanelMatch(lag = 2,\n                    time.id = \"year\",\n                    unit.id = \"ccode\",\n                    treatment = \"pko_term\",\n                    refinement.method = \"ps.weight\",\n                    data = merged,\n                    covs.formula = ~\n                      I(lag(lpop, 1:2)) +\n                      I(lag(lmilper, 1:2)) +\n                      I(lag(ldeaths, 1:2)) +\n                      I(lag(wardur, 1:2)) +\n                      I(lag(democracy, 1:2)),\n                    qoi = \"att\",\n                    outcome.var = \"lgdppc\",\n                    restrict.control.period = 2)\n\nipw_3 <- PanelMatch(lag = 3,\n                    time.id = \"year\",\n                    unit.id = \"ccode\",\n                    treatment = \"pko_term\",\n                    refinement.method = \"ps.weight\",\n                    data = merged,\n                    covs.formula = ~\n                      I(lag(lpop, 1:3)) +\n                      I(lag(lmilper, 1:3)) +\n                      I(lag(ldeaths, 1:3)) +\n                      I(lag(wardur, 1:3)) +\n                      I(lag(democracy, 1:3)),\n                    qoi = \"att\",\n                    outcome.var = \"lgdppc\",\n                    restrict.control.period = 3)\n\nipw_4 <- PanelMatch(lag = 4,\n                    time.id = \"year\",\n                    unit.id = \"ccode\",\n                    treatment = \"pko_term\",\n                    refinement.method = \"ps.weight\",\n                    data = merged,\n                    covs.formula = ~\n                      I(lag(lpop, 1:4)) +\n                      I(lag(lmilper, 1:4)) +\n                      I(lag(ldeaths, 1:4)) +\n                      I(lag(wardur, 1:4)) +\n                      I(lag(democracy, 1:4)),\n                    qoi = \"att\",\n                    outcome.var = \"lgdppc\",\n                    restrict.control.period = 4)\n\n# Create the Composite Covariate Balance Plot\nplot.new()\npar(oma = c(5, 10, 1.5, 0),\n    mar = c(0.8, .9, 1.5, 0.45),\n    mfrow = c(3,4),\n    pty = \"s\")\n\nbalance_scatter(\n  nn_match_5_1,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_5_2,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_5_3,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_5_4,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_10_1,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_10_2,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_10_3,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  nn_match_10_4,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  xaxt = \"n\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  ipw_1,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\"\n)\n\nbalance_scatter(\n  ipw_2,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  ipw_3,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  yaxt = \"n\"\n)\n\nbalance_scatter(\n  ipw_4,\n  data = merged,\n  covariates = c(\"lpop\", \"lmilper\", \"ldeaths\", \"wardur\",\n                 \"democracy\"),\n  main = \"\",\n  x.axis.label = \"\",\n  y.axis.label = \"\",\n  yaxt = \"n\"\n)\n\nmtext(1,text = \"Standardized Mean Difference \\n Before Refinement\",\n      line = 3.5,\n      at = 0.52, outer = TRUE, cex = 1)\nmtext(2, text = \"Standardized Mean Difference \\n After Refinement\",\n      line = 4, outer = TRUE)\nmtext(2, text = \"NN Matching \\n Up to 5\",\n      line = 1.15, at = .82, outer = TRUE,\n      cex = .8)\nmtext(2, text = \"NN Matching \\n Up to 10\",\n      line = 1.15, at = .5, outer = TRUE,\n      cex = .8)\nmtext(2, text = \"IPW\",\n      line = 1.15, at = .16, outer = TRUE,\n      cex = .8)\nmtext(\"One Year Lag\",\n      line = 0, at = 0.125, outer = TRUE, cex = .8)\nmtext(\"Two Year Lag\",\n      line = 0, at = 0.375, outer = TRUE, cex = .8)\nmtext(\"Three Year Lag\",\n      line = 0, at = 0.625, outer = TRUE, cex = .8)\nmtext(\"Four Year Lag\",\n      line = 0, at = .875, outer = TRUE, cex = .8)\n\n\n\n\n\nFigure 3: Covariate Balance for PKO Withdrawals As Treatment\n\n\n\n\nAs demonstrated by Figure Figure 2, when PKO deployment is considered as treatment, all three refinement methods generally improve balance across a variety of lag thresholds. However, among these, IPW is much more effective at reducing standardized mean differences between treated and control covariates. However, as Figure Figure 3 establishes, the ability of all three refinement methods to improve balance generally breaks down when PKO withdrawal is considered as treatment. Overall, these results suggest that the refinement methods improve balance when PKO deployments are considered as treatment. However, when PKO withdrawals are considered as treatment, IPW preforms the best at both improving balance and reducing standardized mean differences (SMD) of covariates to zero. However, in Figures Figure 2 and Figure 3, covariate balance and increased SMD become a greater consequence as the number of lagged periods to match on increases. In particular, refinement methods appear no better at balancing covariates than non-refinement when PKO withdrawals are considered as treatment for nearest-neighbor refinement. However, in this circumstance, IPW generally does well at improving balance and keeping the SMD closer to zero up until four-lagged time periods as criterion for matched sets. Given this, observations will be matched if they share the same pre-treatment period, up to three time periods."
  },
  {
    "objectID": "projects/UN PKOs and Development/index.html#parallel-trends-assessment",
    "href": "projects/UN PKOs and Development/index.html#parallel-trends-assessment",
    "title": "Do UN Peacekeeping Operations Contribute to Economic Development?",
    "section": "Parallel Trends Assessment",
    "text": "Parallel Trends Assessment\nTo account for time-invariant factors creating a baseline difference in outcome between the treated and control units (in addition to allowing this method to project the long-term impact of treatment), this method employs the difference-in-differences (DID) estimator. While a powerful estimator, DID crucially relies on the satisfaction of the parallel trends assumption. That is, prior to treatment, the trend in outcome between eventually-treated and control units was the same. Importantly, this does not require the values of the outcome to be the same for treated and control units. Rather, the parallel trends assumption merely requires that the trend in outcome for treated and control units be stable and increasing, decreasing, or remaining stagnant at the same rate. Figure Figure 4 visualizes the trend in the standardized mean difference for log-transformed GDP per capita between treated and control units over three periods pre-treatment. Regardless of the size of the standardized mean difference between treated and control units, a stable line across the four time periods may suggest that the parallel trends assumption holds. Across different treatment specifications and refinement methods, the line remains fairly constant, lending support to the satisfaction of the parallel trends assumption.\n\n\nCode\nnn_match_5_onset <- PanelMatch(lag = 3,\n                               time.id = \"year\",\n                               unit.id = \"ccode\",\n                               treatment = \"pko_onset\",\n                               refinement.method = \"mahalanobis\",\n                               size.match = 5,\n                               data = merged,\n                               covs.formula = ~ \n                                 I(lag(lpop, 1:3)) +\n                                 I(lag(lmilper, 1:3)) +\n                                 I(lag(ldeaths, 1:3)) +\n                                 I(lag(wardur, 1:3)) +\n                                 I(lag(democracy, 1:3)),\n                               qoi = \"att\",\n                               outcome.var = \"lgdppc\",\n                               lead = 0:8,\n                               use.diagonal.variance.matrix = TRUE,\n                               restrict.control.period = 3)\n\nnn_match_5_term <- PanelMatch(lag = 3,\n                              time.id = \"year\",\n                              unit.id = \"ccode\",\n                              treatment = \"pko_term\",\n                              refinement.method = \"mahalanobis\",\n                              size.match = 5,\n                              data = merged,\n                              covs.formula = ~ \n                                I(lag(lpop, 1:3)) +\n                                I(lag(lmilper, 1:3)) +\n                                I(lag(ldeaths, 1:3)) +\n                                I(lag(wardur, 1:3)) +\n                                I(lag(democracy, 1:3)),\n                              qoi = \"att\",\n                              outcome.var = \"lgdppc\",\n                              lead = 0:8,\n                              use.diagonal.variance.matrix = TRUE,\n                              restrict.control.period = 3)\n  \nnn_match_10_onset <- PanelMatch(lag = 3,\n                                time.id = \"year\",\n                                unit.id = \"ccode\",\n                                treatment = \"pko_onset\",\n                                refinement.method = \"mahalanobis\",\n                                size.match = 10,\n                                data = merged,\n                                covs.formula = ~ \n                                  I(lag(lpop, 1:3)) +\n                                  I(lag(lmilper, 1:3)) +\n                                  I(lag(ldeaths, 1:3)) +\n                                  I(lag(wardur, 1:3)) +\n                                  I(lag(democracy, 1:3)),\n                                qoi = \"att\",\n                                outcome.var = \"lgdppc\",\n                                lead = 0:8,\n                                use.diagonal.variance.matrix = TRUE,\n                                restrict.control.period = 3)\n  \nnn_match_10_term <- PanelMatch(lag = 3,\n                               time.id = \"year\",\n                               unit.id = \"ccode\",\n                               treatment = \"pko_term\",\n                               refinement.method = \"mahalanobis\",\n                               size.match = 10,\n                               data = merged,\n                               covs.formula = ~ \n                                 I(lag(lpop, 1:3)) +\n                                 I(lag(lmilper, 1:3)) +\n                                 I(lag(ldeaths, 1:3)) +\n                                 I(lag(wardur, 1:3)) +\n                                 I(lag(democracy, 1:3)),\n                               qoi = \"att\",\n                               outcome.var = \"lgdppc\",\n                               lead = 0:8,\n                               use.diagonal.variance.matrix = TRUE,\n                               restrict.control.period = 3)\n  \nipw_onset <- PanelMatch(lag = 3,\n                        time.id = \"year\",\n                        unit.id = \"ccode\",\n                        treatment = \"pko_onset\",\n                        refinement.method = \"ps.weight\",\n                        data = merged,\n                        covs.formula = ~\n                          I(lag(lpop, 1:3)) +\n                          I(lag(lmilper, 1:3)) +\n                          I(lag(ldeaths, 1:3)) +\n                          I(lag(wardur, 1:3)) +\n                          I(lag(democracy, 1:3)),\n                        qoi = \"att\",\n                        outcome.var = \"lgdppc\",\n                        lead = 0:8,\n                        restrict.control.period = 3)\n  \nipw_term <- PanelMatch(lag = 3,\n                       time.id = \"year\",\n                       unit.id = \"ccode\",\n                       treatment = \"pko_term\",\n                       refinement.method = \"ps.weight\",\n                       data = merged,\n                       covs.formula = ~\n                         I(lag(lpop, 1:3)) +\n                         I(lag(lmilper, 1:3)) +\n                         I(lag(ldeaths, 1:3)) +\n                         I(lag(wardur, 1:3)) +\n                         I(lag(democracy, 1:3)),\n                       qoi = \"att\",\n                       outcome.var = \"lgdppc\",\n                       lead = 0:8,\n                       restrict.control.period = 3)\n\n# Begin Creating the Graphic\nplot.new()\npar(oma = c(5, 10, 1.5, 0),\n    mar = c(0.8, .9, 1.5, 0.45),\n    mfrow = c(2,3),\n    pty = \"s\")\n\nget_covariate_balance(nn_match_5_onset$att,\n                      data = merged,\n                      covariates = c(\"lgdppc\"),\n                      plot = TRUE,\n                      ylim = c(-2, 2),\n                      ylab = \"\",\n                      legend = FALSE)\nabline(v = 3, lty = \"dotted\")\n\nget_covariate_balance(nn_match_10_onset$att,\n                      data = merged,\n                      covariates = c(\"lgdppc\"),\n                      plot = TRUE,\n                      ylim = c(-2, 2),\n                      ylab = \"\",\n                      legend = FALSE,\n                      yaxt = \"n\")\nabline(v = 3, lty = \"dotted\")\n\nget_covariate_balance(ipw_onset$att,\n                      data = merged,\n                      covariates = c(\"lgdppc\"),\n                      plot = TRUE,\n                      ylim = c(-2, 2),\n                      ylab = \"\",\n                      legend = FALSE,\n                      yaxt = \"n\")\nabline(v = 3, lty = \"dotted\")\n\nget_covariate_balance(nn_match_5_term$att,\n                      data = merged,\n                      covariates = c(\"lgdppc\"),\n                      plot = TRUE,\n                      ylim = c(-2, 2),\n                      ylab = \"\",\n                      legend = FALSE)\nabline(v = 3, lty = \"dotted\")\n\nget_covariate_balance(nn_match_10_term$att,\n                      data = merged,\n                      covariates = c(\"lgdppc\"),\n                      plot = TRUE,\n                      ylim = c(-2, 2),\n                      ylab = \"\",\n                      legend = FALSE,\n                      yaxt = \"n\")\nabline(v = 3, lty = \"dotted\")\n\nget_covariate_balance(ipw_term$att,\n                      data = merged,\n                      covariates = c(\"lgdppc\"),\n                      plot = TRUE,\n                      ylab = \"\",\n                      ylim = c(-2, 2),\n                      yaxt = \"n\",\n                      legend = FALSE)\nabline(v = 3, lty = \"dotted\")\n\nmtext(1,text = \"Years Before Treatment\",\n      line = 3.5,\n      at = 0.5, outer = TRUE, cex = 1)\nmtext(2, text = \"Standardized Mean Difference\",\n      line = 4, outer = TRUE)\nmtext(2, text = \"PKO Deployment\",\n      line = 1.5, at = .73, outer = TRUE,\n      cex = .8)\nmtext(2, text = \"PKO Withdrawal\",\n      line = 1.5, at = .23, outer = TRUE,\n      cex = .8)\nmtext(\"NN Matching - Up to 5 \\n\",\n      line = -2, at = 0.17, outer = TRUE, cex = .8)\nmtext(\"NN Matching - Up to 10 \\n\",\n      line = -2, at = 0.5, outer = TRUE, cex = .8)\nmtext(\"IPW \\n \",\n      line = -2, at = 0.83, outer = TRUE, cex = .8)\n\n\n\n\n\nFigure 4: Parallel Trends Assessment"
  },
  {
    "objectID": "projects/UN PKOs and Development/index.html#economic-effects-of-pkos",
    "href": "projects/UN PKOs and Development/index.html#economic-effects-of-pkos",
    "title": "Do UN Peacekeeping Operations Contribute to Economic Development?",
    "section": "Economic Effects of PKOs",
    "text": "Economic Effects of PKOs\nWith improved balance and evidence supporting the satisfaction of the parallel trends assumption, we can now turn to the results of this analysis. However, prior to a discussion of the estimates themselves, it is worth clearly identifying what causal effect is being estimated in the first place. It is not possible to make any broad claims concerning the causal effect of UN PKOs if they were applied to any country within the population of all countries globally. That is, it is not possible to answer the question, “what would the average effect of UN PKOs on economic development be if applied to a cases that never received UN PKOs?”. This question is one that can be answered when the average treatment effect (ATE) is estimated. However, the ATE is not estimated because there are a range of cases in which UN PKOs would never intervene in for a variety of observed and unobserved reasons (we cannot extrapolate these results to a country such as Sweden or Japan in 2023) and the entire population of country-year observations is not included in the analysis due to the restrictions of matching. Barring randomization of treatment and the execution of a randomized controlled trial, the estimation of the ATE is not a possibility in this scenario given the issue of unobserved confounding. Instead, the average treatment effect on the treated (ATT) is generated, which can answer the question, “what was the average effect of UN PKOs on economic development where UN PKOs were deployed?”\nTurning to the results as presented in Figure Figure 5, no statistically significant effect is reported for PKO withdrawals in the eight years following PKO withdrawals, although as expected, the estimate is increasingly negative. This is true for all refinement methods, although, the substantive impact is the largest and the confidence intervals overlap with zero the least when IPW is employed for refinement. Given that, for PKO withdrawals, IPW improved balance the best, these results should be interpreted with the greatest degree of confidence. However, a perhaps more interesting finding are the estimates for the effects of PKO deployments. Across all three refinement methods, covariate balance tended to overwhelmingly improve when PKO deployments were considered as treatment. Although, by far, IPW preformed the best at reducing the SMD closer to zero. Consequentially, results obtained using IPW should be interpreted with more confidence than results obtained using nearest-neighbor matching. For nearest-neighbor matching-derived estimates, the effect of UN PKO deployments on economic development eight years following deployment is statistically significant. Confidence intervals for estimates derived from IPW marginally overlap with zero. Substantively speaking, the average effect of UN PKO deployments for units that received UN PKO deployments after eight years is a 34% (nearest-neighbor matching, up to 5 units), 28% (nearest-neighbor matching, up to 10 units), and a 27% (IPW) decrease in GDP per capita. These findings stand in stark contrast to prior research suggesting a positive relationship between PKOs and economic conditions (Caruso et al. 2017; Beber et al. 2019; Bove, Salvatore, and Elia 2021). In contrast, these results are well in line with other findings employing quasi-experimental designs where the economic effect of UN PKOs is largely negligible or even negative (Bove and Elia 2017; Mvukiyehe and Samii 2020). In the following paragraphs, I discuss what might be driving these contrasting findings.\n\n\nCode\n# NN Up to 5 Matches: Onset\nnn_5_onset_res <- PanelEstimate(\n  sets = nn_match_5_onset,\n  data = merged,\n  se.method = \"conditional\",\n  number.iterations = 500,\n  confidence.level = .95\n)\n\n# NN Up to 10 Matches: Onset\nnn_10_onset_res <- PanelEstimate(\n  sets = nn_match_10_onset,\n  data = merged,\n  se.method = \"conditional\",\n  number.iterations = 500,\n  confidence.level = .95\n)\n\n# IPW: Onset\nipw_onset_res <- PanelEstimate(\n  sets = ipw_onset,\n  data = merged,\n  se.method = \"conditional\",\n  number.iterations = 500,\n  confidence.level = .95\n)\n\n# NN Up to 5 Matches: Withdrawal\nnn_5_term_res <- PanelEstimate(\n  sets = nn_match_5_term,\n  data = merged,\n  se.method = \"conditional\",\n  number.iterations = 500,\n  confidence.level = .95\n)\n\n# NN Up to 10 Matches: Withdrawal\nnn_10_term_res <- PanelEstimate(\n  sets = nn_match_10_term,\n  data = merged,\n  se.method = \"conditional\",\n  number.iterations = 500,\n  confidence.level = .95\n)\n\n# IPW: Withdrawal\nipw_term_res <- PanelEstimate(\n  sets = ipw_term,\n  data = merged,\n  se.method = \"conditional\",\n  number.iterations = 500,\n  confidence.level = .95\n)\n\nplot.new()\npar(oma = c(5, 10, 1.5, 0),\n    mar = c(0.8, .9, 1.5, 0.45),\n    mfrow = c(2,3),\n    pty = \"s\")\n\nplot(nn_5_onset_res,\n     main = \"\",\n     xlab = \"\",\n     ylab = \"\")\nabline(v = 1, lty = \"dotted\")\n\nplot(nn_10_onset_res,\n     main = \"\",\n     xlab = \"\",\n     ylab = \"\")\nabline(v = 1, lty = \"dotted\")\n\nplot(ipw_onset_res,\n     main = \"\",\n     xlab = \"\",\n     ylab = \"\")\nabline(v = 1, lty = \"dotted\")\n\nplot(nn_5_term_res,\n     main = \"\",\n     xlab = \"\",\n     ylab = \"\")\nabline(v = 1, lty = \"dotted\")\n\nplot(nn_10_term_res,\n     main = \"\",\n     xlab = \"\",\n     ylab = \"\")\nabline(v = 1, lty = \"dotted\")\n\nplot(ipw_term_res,\n     main = \"\",\n     xlab = \"\",\n     ylab = \"\")\nabline(v = 1, lty = \"dotted\")\n\nmtext(1,text = \"Years After Treatment\",\n      line = 3.5,\n      at = 0.5, outer = TRUE, cex = 1)\nmtext(2, text = \"Estimated Effect of \\n PKO Deployment\",\n      line = 2.5, at = .725, outer = TRUE,\n      cex = .8)\nmtext(2, text = \"Estimated Effect of \\n PKO Withdrawal\",\n      line = 2.5, at = .225, outer = TRUE,\n      cex = .8)\nmtext(\"NN Matching - Up to 5 \\n\",\n      line = -2, at = 0.17, outer = TRUE, cex = .8)\nmtext(\"NN Matching - Up to 10 \\n\",\n      line = -2, at = 0.5, outer = TRUE, cex = .8)\nmtext(\"IPW \\n \",\n      line = -2, at = 0.83, outer = TRUE, cex = .8)\n\n\n\n\n\nFigure 5: Estimated Average Effects of PKO Deployments and Withdrawals on Economic Development\n\n\n\n\nOne clear explanation for the wide variation in findings is the wide variety of samples, methods, operationalizations of outcome, and levels of aggregation used in quasi-experimental designs seeking to isolate the economic effects of PKOs. Samples range from country-year level analyses (Bove and Elia 2017; Beber et al. 2019) to sub-national coverage including South Sudanese counties (Caruso et al. 2017) and household-level survey data in South Sudan (Bove, Salvatore, and Elia 2021) and Liberia (Beber et al. 2019; Mvukiyehe and Samii 2020). Quasi-experimental methods include matching (Beber et al. 2019; Mvukiyehe and Samii 2020), instrumental variables (Caruso et al. 2017; Bove, Salvatore, and Elia 2021), fixed effects (Beber et al. 2019; Mvukiyehe and Samii 2020; Bove, Salvatore, and Elia 2021), the synthetic control method (Bove and Elia 2017), and mediation analysis (Bove, Salvatore, and Elia 2021). In these studies, economic development has been operationalized as GDP per capita (Bove and Elia 2017), GDP per capita growth (Beber et al. 2019), cereal production (Caruso et al. 2017), and various household-level survey indicators of development and economic well-being (Beber et al. 2019; Mvukiyehe and Samii 2020; Bove, Salvatore, and Elia 2021). Like any emerging literature, more work simply needs to be done. The number of quasi-experimental designs studying the economic effects of PKOs is simply too small and too diverse in methods and data to create any declarative statements. Future research should experiment with a wide range of methods, data, and operationalizations of development to determine if any bias exists dependent on the selection of certain methods, data, etc.\nIn addition to the broad inconsistency in findings within existing literature, there are likewise a number of issues with this research design that, if improved, may generate alternative results. First, not all PKOs are the same. Mission goals, troop deployment, police deployment, and a host of various mission-specific factors will vary heavily across different missions. Treating all PKOs as a uniform binary treatment is convenient for the purposes of executing quasi-experimental designs, but it is not ideal for estimating an exact ATT. Future studies should incorporate the variation in treatment within research designs. While this does complicate the development of quasi-experimental designs, it is likely a necessary step in the right direction. Second, a brief return to the stable unit treatment value assumption (SUTVA) is warranted. Treatment spillover effects between countries remains a serious threat to causal inference. In particular, researchers extending quasi-experimental designs to the study of the potentially conflict-reducing effects of PKOs should proceed with great caution given the contagious nature of conflict and the geographically clustered nature of countries that receive UN PKOs."
  },
  {
    "objectID": "projects/UN PKOs and Development/index.html#sensitivity-analysis-1",
    "href": "projects/UN PKOs and Development/index.html#sensitivity-analysis-1",
    "title": "Do UN Peacekeeping Operations Contribute to Economic Development?",
    "section": "Sensitivity Analysis",
    "text": "Sensitivity Analysis\nAs noted in the research design, extant sensitivity analyses are not currently supported for the panel data matching design as implemented by Imai, Kim, and Wang (2021). Rather than estimating the sensitivity of estimates from the matching analysis executed in this paper, I estimate the sensitivity of the PKO coefficient generated from a standard linear regression model. Importantly, the results of this sensitivity analysis are not generalizable to the analysis conducted in this paper. However, I choose to execute this analysis to demonstrate the sensitivity of coefficients in research designs that are much more common in the PKO literature than the analysis conducted for this paper. The execution of this sensitivity analysis is intended to demonstrate the issue of unobserved confounding in standard research designs using statistical control. For the following sensitivity analysis, I estimate a linear regression model where logged GDP per capita is regressed on a dummy variable indicating the presence of a PKO, logged population size, logged count of deaths (battle-related and one-sided violence), logged military personnel per capita, war duration, and democracy, measured using V-Dem’s electoral democracy index. The results of the sensitivity analysis are presented in Figure Figure 6.\n\n\nCode\n# Create Base Model With No Matching\nmerged <- merged %>% # Renaming for Better Label on the Plot\n  rename(MPpc = lmilper)\n\nm1 <- lm(lgdppc ~ pko + MPpc + lpop + ldeaths + wardur + democracy, \n         data = merged)\n\n# Create and Visualize the Sensitivity Estimates\nsens_results <- sensemakr(m1, treatment = \"pko\", \n                          benchmark_covariates = \"MPpc\",\n                          kd = c(0.25, 0.5))\n\n# Renaming Labels for Better Punctuation\nx_lab <- expression(Partial ~ R^2 ~ of ~ Confounders(s) ~ With ~ the ~ Outcome)\ny_lab <- expression(Partial ~ R^2 ~ of ~ Confounders(s) ~ With ~ the ~ Treatment)\n\nplot(sens_results, \n     ylab = x_lab, \n     xlab = y_lab)\n\n\n\n\n\nFigure 6: Sensitivity Analysis for Unobserved Confounders Using Standard Statistical Control\n\n\n\n\nBecause the size of a government’s military capability likely has a great degree of influence on the presence of a UN PKO (the UN may be hesitant to engage/stay in a conflict where the government is more capable) and the prospects for political stability and development, logged military personnel per capita (MPpc) is selected as a benchmark covariate. Simply put, this means that unobserved confounders are interpreted in reference to the size of the relationship between economic development and MPpc. The coefficient for PKO as determined by the linear regression model is -0.11 (the unadjusted black triangle in Figure Figure 6). If an unobserved confounder with a relationship with GDP per capita 0.25x as strong as the relationship between MPpc and GDP per capita was specified in the linear regression model, the PKO coefficient would increase to -0.05. If an unobserved confounder was 0.5x as strong, the sign on the coefficient for PKO would flip (0.013), demonstrating a positive association between PKOs and economic development. To meaningfully interpret these results, two items must be considered. First, another researcher may easily be able to mention and include another confounder that is not specified in the regression model. An inclusion of such variables could easily alter the coefficient for PKO. Indeed, the results of the sensitivity analysis suggests the possibility of this is high, assuming an unspecified confounder at least 0.5x as strong as MPpc is plausible. This assumption leads to the second item to consider. Is an unspecified confounder 0.5x as strong as MPpc a realistic possibility? No statistic can answer this question. From here, expert domain knowledge, available theoretical literature, and awareness of data availability must inform the interpretation of the plausibility of such a confounder."
  },
  {
    "objectID": "resume/index.html",
    "href": "resume/index.html",
    "title": "Resume",
    "section": "",
    "text": "Download Current Resume"
  }
]