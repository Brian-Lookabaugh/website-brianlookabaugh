[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brian Lookabaugh",
    "section": "",
    "text": "Greetings and welcome to my personal website! My name is Brian Lookabaugh and I am a Research Analyst at Fors Marsh. In my position, I leverage my skills in data analysis and statistical modeling to solve a variety of business problems. These include descriptive tasks (creating visualizations to communicate trends and patterns), predictive problems (utilizing machine learning to predict outcomes and forecast), and causal questions (drawing on my background in causal inference to answer questions such as “did X have an impact on Y?”).\n\nOutside of my professional role, I routinely refine and expand my methodological toolkit by researching new methods and applying my skill set to other recreational interests of mine. You can find some of these passion projects under the “Blog” section of this site. If you have any questions about my research, please feel free to reach out to me!"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "My personal research covers the intersection of causal inference, quasi-experimental design, and policy evaluation and a variety of topics that I find interesting, including (but not limited to): peace and conflict, democracy and elections, political and economic development, and the NFL (professional American football)."
  },
  {
    "objectID": "research/index.html#dissertation",
    "href": "research/index.html#dissertation",
    "title": "Research",
    "section": "Dissertation",
    "text": "Dissertation\n\n“Rethinking the Study of Conflict and Peace: Making Causal Inferences in Quantitative Conflict and Peace Research” \n\nManuscript \nCode (Chapter 2) \nCode (Chapter 3)"
  },
  {
    "objectID": "resume/index.html",
    "href": "resume/index.html",
    "title": "Brian Lookabaugh",
    "section": "",
    "text": "Download"
  },
  {
    "objectID": "blog/2024/roadtrip-replication/index.html",
    "href": "blog/2024/roadtrip-replication/index.html",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "",
    "text": "One of the primary goals of science is to examine causal relationships. Anytime a researcher asks a question like, “how does \\(X\\) impact \\(Y\\)?” or “do changes in \\(X\\) cause a change in \\(Y\\)?” that researcher is at the very beginning of a causal research design. Unfortunately, asking causal questions is a lot easier than answering them.1\nIt would be great if a researcher could simply look for a correlation between \\(X\\) and \\(Y\\) and determine whether \\(X\\) causes a change in \\(Y\\). However, inferring causation from a bi-variable test or a scatterplot is very, very poor practice. One of the biggest reasons why we can’t do this is because of confounding, which refers to things that cause some change in both \\(X\\) and \\(Y\\) (in notation: \\(X\\) \\(\\leftarrow\\) \\(Z\\) \\(\\rightarrow\\) \\(Y\\)) and, if not accounted for, will result in a misleading picture on the relationship between \\(X\\) and \\(Y\\). A somewhat canonical example to illustrate the problem of un-adjusted confounding is the relationship between ice cream sales (\\(X\\)) and shark attacks (\\(Y\\)).\n\n\nCode\n# Create Simulated Data\ndays &lt;- 365 # Number of Days in a Year\ntemp &lt;- pmin(pmax(rnorm(days, mean = 70, sd = 10), 30), 100) # Temperature\nshark &lt;- 0.5 + 0.1 * (temp - 70) + rnorm(days, mean = 0.5, sd = 0.5) # Shark Attacks\nshark &lt;- pmax(shark, 0) # Lowest Shark Attacks Can Go Is Zero\nshark &lt;- floor(shark) # Round This Down (There Can't Be Any 0.5 Shark Attacks)\nice &lt;- 15000 + 250 * (temp - 70) + rnorm(days, mean = 2500, sd = 500) # Ice Cream Sales with Random Variation\nsim &lt;- data.frame(days, temp, shark, ice) # Combine Data\n\n# Create a Scatter Plot\nggplot(sim, aes(x = ice, y = shark)) + \n  geom_point() + \n  labs(x = \"Ice Cream Sales per Day\", y = \"Shark Attacks per Day\", title = \"\") + \n  ylim(0, 4) +\n  blog_theme()\n\n\n\n\n\n\n\n\n\nThis plot is why we don’t infer causation from a bi-variable relationship. (This plot also uses totally fake data and it’s only here to serve as a theoretical example… Sharks really don’t attack this many people annually, but I really don’t like them so ¯\\_(ツ)_/¯ ). If we did, then we could conclude one should never risk swimming in the ocean after consuming ice cream. However, as you can see in the following graph, once we take temperature into account, the ice cream sales-shark attack-pipeline theory is certainly much less compelling. However, the point remains. If we were to remove all of the variation in the relationship between \\(X\\) and \\(Y\\) that is explained by the confounders, then the bi-variable correlation between \\(X\\) and \\(Y\\) would be the causal effect.2\n\n\nCode\nggplot(sim, aes(x = ice, y = shark, color = temp)) + \n  geom_point() + \n  labs(x = \"Ice Cream Sales per Day\", y = \"Shark Attacks per Day\", \n       title = \"\", color = \"Temperature\") + \n  scale_color_gradientn(colors = c(\"blue\", \"white\", \"red\"), limits = c(30, 100)) +  \n  ylim(0, 4) +\n  blog_theme()\n\n\n\n\n\n\n\n\n\nIn an ideal world, a researcher is able to utilize a randomized experiment to answer their causal question. Randomized experiments are incredibly valuable because the “treatment” (also known as “\\(X\\)”, the independent variable of interest, the exposure, etc.) is randomly allocated across the participants/units in the study. If treatment is randomly allocated then we’ve taken care of our confounders because \\(Z\\) \\(\\rightarrow\\) \\(X\\) is no longer true. The only thing that impacts \\(X\\) is pure chance (randomization). Sure, participants/units have characteristics that might make them more or less likely to respond to treatment in a certain way. But we don’t need to control for this because those same individuals are just as likely to be in the control group because pure chance determined their treatment status. Therefore, while randomization does not allow us to estimate causal effects for each individual within a study, we can estimate causal effects on average for the “populations” they represent by comparing the average outcome (\\(Y\\)) between the two groups (treated and control).\nBut experiments are pretty rare and are practically hard to pull off. They take time to design and to administer. It’s certainly a lot easier to just download your favorite data set and plug variables into a regression model.3 In some cases, experiments are impossible to pull off. For example, my academic background is in the study of armed conflict and violence. If I want to run an experiment to evaluate the effect of democracy on civil violence… well, you can see where that gets very tricky. How am I supposed to randomly allocate which countries get to be democracies and which don’t? And this leads to the third point. Even if this bizarre experiment was possible and I had the political clout to pull that off, it would certainly not be very ethical.\nSo, absent experiments, we find ourselves in a less-than-desirable state. Because now, we have to manually identify, collect, and appropriately control for all confounders that the experiment otherwise would have taken care of for us via randomization. This really is not a small task at all if you sit and think about it. How do I know that I’ve identified all of the confounders? What if I can’t measure some of them? If I omit a confounder (or several) how can I know how much of an impact their omission had on my analysis? What if I control for a variable that isn’t a confounder? These are great questions and they highlight the reality that confounding will be a problem in your design which renders your original causal question incredibly difficult to reliably answer. I won’t be covering these problems in this blog, but tools like directed acyclic graphs (DAGs), simulation, and sensitivity analyses are very helpful and I would highly recommend spending some time to learn about them (although, none of these tools solve the problem of un-adjusted confounding and plugging as many control variables into your regression is almost always going to harm more than it will help).4\nRather than spending time on these serious problems, I am going to introduce another problem that is often under-appreciated and less discussed than other prominent topics in the causal inference literature. It turns out that when you’re examining multiple units (individuals, firms, schools, countries, etc.) over time, the analysis gets a bit more complicated and requires more robust solutions than what are often employed."
  },
  {
    "objectID": "blog/2024/roadtrip-replication/index.html#footnotes",
    "href": "blog/2024/roadtrip-replication/index.html#footnotes",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote: if you are already familiar with the core concepts of causal inference, feel free to skip down to the section where I start discussing time and why it messes things up.↩︎\nWell… kind of. There are actually a lot of other assumptions that you would need to check for first, like positivity, SUTVA, no measurement error, etc. (which will not be covered here in sufficient detail if you are not familiar with these topics). If you’re not super familiar with these topics, I highly recommend checking out Chatton and Rohrer 2024.↩︎\nI do not condone this attitude… never treat your regressions or research designs this way.↩︎\nHere are some good starting materials for DAGs, simulation, and sensitivity analyses: Rohrer 2018, Blair et al. 2023, Cinelli and Hazlett 2020.↩︎"
  },
  {
    "objectID": "blog/index.html#section",
    "href": "blog/index.html#section",
    "title": "Blog",
    "section": "2024",
    "text": "2024\n\n\n\n\n\n\n\n\n\n\nPredicting the 2024-2025 NFL Season\n\n\n\n\n\n\nmachine learning\n\n\nnfl\n\n\n\nFollow my attempts to forecast NFL standings for the upcoming season using vibes and (more importantly), simulations, and machine learning.\n\n\n\n\n\nJuly 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAn Introduction to Dynamic Causal Inference\n\n\n\n\n\n\ncausal inference\n\n\npanel data\n\n\ndags\n\n\n\nLearn the basics to making causal inferences with panel/longitudinal data.\n\n\n\n\n\nJuly 8, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2024/index.html",
    "href": "blog/2024/index.html",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "",
    "text": "Code\n# Load Libraries\npacman::p_load(\n  \"dplyr\", # Data Manipulation\n  \"ggplot2\", # Data Visualization\n  \"ggtext\", # Labels\n  \"dagitty\", # Creating DAGs\n  \"ggdag\", # Plotting DAGs\n  install = FALSE\n)\n\n# Define a Custom Theme - Taken From Andrew Heiss's Blogs\nblog_theme &lt;- function() {\n  theme_bw() +  # Start with theme_bw\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.background = element_rect(fill = \"white\", color = NA),\n      plot.title = element_text(face = \"bold\"),\n      axis.title = element_text(face = \"bold\"),\n      strip.text = element_text(face = \"bold\"),\n      strip.background = element_rect(fill = \"grey80\", color = NA),\n      legend.title = element_text(face = \"bold\")\n    )\n}"
  },
  {
    "objectID": "blog/2024/index.html#footnotes",
    "href": "blog/2024/index.html#footnotes",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote: if you are already familiar with the core concepts of causal inference, feel free to skip down to the section where I start discussing time and why it messes things up.↩︎\nWell… kind of. There are actually a lot of other assumptions that you would need to check for first, like positivity, SUTVA, no measurement error, etc. (which will not be covered here in sufficient detail if you are not familiar with these topics). If you’re not super familiar with these topics, I highly recommend checking out Chatton and Rohrer 2024.↩︎\nI do not condone this attitude… never treat your regressions or research designs this way.↩︎\nHere are some good starting materials for DAGs, simulation, and sensitivity analyses: Rohrer 2018, Blair et al. 2023, Cinelli and Hazlett 2020.↩︎"
  },
  {
    "objectID": "blog/2024/dynamic-causal-inference/index.html",
    "href": "blog/2024/dynamic-causal-inference/index.html",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "",
    "text": "Code\n# Load Libraries\npacman::p_load(\n  \"dplyr\", # Data Manipulation\n  \"ggplot2\", # Data Visualization\n  \"ggtext\", # Labels\n  \"dagitty\", # Creating DAGs\n  \"ggdag\", # Plotting DAGs\n  install = FALSE\n)\n\n# Define a Custom Theme - Taken From Andrew Heiss's Blogs\nblog_theme &lt;- function() {\n  theme_bw() +  # Start with theme_bw\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.background = element_rect(fill = \"white\", color = NA),\n      plot.title = element_text(face = \"bold\"),\n      axis.title = element_text(face = \"bold\"),\n      strip.text = element_text(face = \"bold\"),\n      strip.background = element_rect(fill = \"grey80\", color = NA),\n      legend.title = element_text(face = \"bold\")\n    )\n}"
  },
  {
    "objectID": "blog/2024/dynamic-causal-inference/index.html#footnotes",
    "href": "blog/2024/dynamic-causal-inference/index.html#footnotes",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote: if you are already familiar with the core concepts of causal inference, feel free to skip down to the section where I start discussing time and why it messes things up.↩︎\nWell… kind of. There are actually a lot of other assumptions that you would need to check for first, like positivity, SUTVA, no measurement error, etc. (which will not be covered here in sufficient detail if you are not familiar with these topics). If you’re not super familiar with these topics, I highly recommend checking out Chatton and Rohrer 2024.↩︎\nI do not condone this attitude… never treat your regressions or research designs this way.↩︎\nHere are some good starting materials for DAGs, simulation, and sensitivity analyses: Rohrer 2018, Blair et al. 2023, Cinelli and Hazlett 2020.↩︎"
  },
  {
    "objectID": "blog/2024/predicting-2024-nfl-season/index.html",
    "href": "blog/2024/predicting-2024-nfl-season/index.html",
    "title": "Predicting the 2024-2025 NFL Season",
    "section": "",
    "text": "Code\n# Load Libraries\npacman::p_load(\n  \"dplyr\", # Data Manipulation\n  \"nflverse\", # NFL Verse Environment\n  \"gt\", # Nice Tables\n  \"tidyr\", # Reshaping Data\n  \"stringr\", # Working with Strings\n  install = FALSE\n)\n\n# Define a Custom Theme - Taken From Andrew Heiss's Blogs\nblog_theme &lt;- function() {\n  theme_bw() +  # Start with theme_bw\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.background = element_rect(fill = \"white\", color = NA),\n      plot.title = element_text(face = \"bold\"),\n      axis.title = element_text(face = \"bold\"),\n      strip.text = element_text(face = \"bold\"),\n      strip.background = element_rect(fill = \"grey80\", color = NA),\n      legend.title = element_text(face = \"bold\")\n    )\n}\n\n\n\nMy Vibes-Based Predictions\nI am a massive fan of professional American football. During the NFL season, I am treated to exciting games, interesting storylines, and cheap (but entertaining) drama generated by the sports media. However, when the NFL season ends, I have to be really creative to get my NFL “fix” in. One thing that I really look forward to in the NFL off-season is the schedule release. Once the schedule is released, I can go game-by-game and predict which team will win that match-up. I do this several times during the off-season, and I generally notice a consensus from my predictions (see below:)\n\n\nCode\n# Create My Vibes Tribble - Adding Extra Spacing\nvibes &lt;- tribble(\n  ~east, ~record_1, ~space_1, ~north, ~record_2, ~space_2, ~south, ~record_3, ~space_3, ~west, ~record_4, ~conf,\n  \"BUF\", \"10-7\", \" \", \"BAL\", \"13-4\", \" \", \"IND\", \"13-4\", \" \", \"KC\", \"12-5\", \"AFC\",\n  \"NYJ\", \"9-8\", \" \", \"CIN\", \"10-7\", \" \", \"HOU\", \"11-6\", \" \", \"LAC\", \"11-6\", \"AFC\",\n  \"MIA\", \"7-10\", \" \", \"PIT\", \"8-9\", \" \",\"TEN\", \"9-8\", \" \", \"DEN\", \"7-10\", \"AFC\",\n  \"NE\", \"3-14\", \" \", \"CLE\", \"8-9\", \" \", \"JAX\", \"9-8\", \" \", \"LV\", \"6-11\", \"AFC\",\n  \"PHI\", \"9-8\", \" \", \"GB\", \"12-5\", \" \", \"ATL\", \"9-8\", \" \", \"LAR\", \"11-6\", \"NFC\",\n  \"WSH\", \"8-9\", \" \", \"DET\", \"11-6\", \" \", \"TB\", \"7-10\", \" \", \"SF\", \"10-7\", \"NFC\",\n  \"DAL\", \"7-10\", \" \", \"CHI\", \"9-8\", \" \", \"CAR\", \"5-12\", \" \", \"ARZ\", \"9-8\", \"NFC\",\n  \"NYG\", \"5-12\", \" \", \"MIN\", \"6-11\", \" \", \"NO\", \"4-13\", \" \", \"SEA\", \"4-13\", \"NFC\"\n)\n\nvibes %&gt;%\n  # Group By Conference\n  gt(groupname_col = \"conf\") %&gt;%\n  # Create Columns Labels\n  cols_label(\n    east = \"\",\n    record_1 = \"East\",\n    space_1 = \"\",\n    north = \"\",\n    record_2 = \"North\",\n    space_2 = \"\",\n    south = \"\",\n    record_3 = \"South\",\n    space_3 = \"\",\n    west = \"\",\n    record_4 = \"West\"\n  ) %&gt;%\n  # Align Column Title Text\n  tab_style(style = cell_text(align = \"center\"), locations = cells_column_labels()) %&gt;%\n  # Align Body Text\n  tab_style(style = cell_text(align = \"center\"), locations = cells_body()) %&gt;%\n  # Distinguish Division Rows\n  tab_style(\n    style = list(\n      cell_fill(color = \"#bcc0be\")),\n    locations = cells_body(rows = which(vibes$east %in% c(\"AFC\", \"NFC\")))) %&gt;%\n  # Add Team Logos\n  nflplotR::gt_nfl_logos(columns = c(\"east\", \"north\", \"south\", \"west\"))\n\n\n\n\n\n\n\n\n\nEast\n\n\nNorth\n\n\nSouth\n\n\nWest\n\n\n\n\nAFC\n\n\n\n10-7\n\n\n13-4\n\n\n13-4\n\n\n12-5\n\n\n\n9-8\n\n\n10-7\n\n\n11-6\n\n\n11-6\n\n\n\n7-10\n\n\n8-9\n\n\n9-8\n\n\n7-10\n\n\n\n3-14\n\n\n8-9\n\n\n9-8\n\n\n6-11\n\n\nNFC\n\n\n\n9-8\n\n\n12-5\n\n\n9-8\n\n\n11-6\n\n\n\n8-9\n\n\n11-6\n\n\n7-10\n\n\n10-7\n\n\n\n7-10\n\n\n9-8\n\n\n5-12\n\n\n9-8\n\n\n\n5-12\n\n\n6-11\n\n\n4-13\n\n\n4-13\n\n\n\n\n\n\n\nAs you can see, I have some fairly tame predictions: the Chiefs will be really good, the Falcons will win the division with a mediocre record, the Giants will not be good, etc. However, I like to think that I generally make bold predictions every year. For example, I have the AFC East having a pretty low win-total. I have the Colts breaking out and taking the AFC South from the Texans. I have the NFC East reverting to the NFC Least (and my Cowboys missing the playoffs). I have the 49ers regressing a bit.\nBut, all of this is just based on my gut, and I thought it would be cool to look into NFL forecasting tools and see how much these tools correspond with my intuition (and, to see who was more right once the 2024 NFL regular season is over). So, that is what I will be attempting with this blog post. I am going to compare my vibes-based forecasts with three other forecasts; {nflseedR}’s predictions based on 100 simulated seasons, a machine learning algorithm using simple NFL-metrics as predictors, and a machine learning algorithm using advanced NFL-metrics as predictors.\n\n\nPredictions Using {nflseedR}\nAs it turns out, NFL analytics are well-supported in R. In fact, a collection of packages known as the “nflverse” supply the interested R user within tons of tools that make their NFL analytics experience much richer and easier. For the purposes of this blog post, I am going to rely on the {nflseedR} package, which allows users to simulate entire seasons. In my iteration below, I am simulating the 2024 NFL season 100 times. I then take the average wins for each team and round them, then I compute their losses by taking the total number of games (17) minus their average rounded wins.\nTo build dramatic suspense, I won’t show you how these results compared to my vibes-based results until the end of this blog. However, you might be interested in how {nflseedR} predicts wins over the course of 100 simulated seasons. A really cool things about {nflseedR} is that you can input your own model into the simulate_nfl() function and it will go through each game and make predictions for you with your own model. So, what happens when you don’t specify a model like I did? I’m not really sure! It’s kind of vague from what I can tell from my research… and needless to say, some of these predicted standings are very bold. So, I wouldn’t put much stock in these.\n\n# Run the Simulation\nseed_sims &lt;- simulate_nfl(nfl_season = 2024, simulations = 100)\n\nWarning: package 'purrr' was built under R version 4.2.3\n\n# Extract Information From the Simulations\nseed_wins &lt;- seed_sims$teams %&gt;%\n  select(conf, division, team, wins) %&gt;%\n  # Calculate Average Wins\n  group_by(conf, team, division) %&gt;%\n  summarise(wins = mean(wins)) %&gt;%\n  ungroup() %&gt;%\n  # Calculate Losses\n  mutate(wins = round(wins),\n         losses = 17 - wins) %&gt;%\n  # Create Standings as a Character\n  mutate(record = paste(wins, losses, sep = \"-\")) %&gt;%\n  # Extract Cardinal Direction\n  mutate(direction = str_extract(division, \"(?&lt;=\\\\s).+$\")) %&gt;%\n  # Within Each Division, Order By Wins\n  arrange(direction, division, desc(wins)) %&gt;%\n  # Remove Old Columns\n  dplyr::select(-c(wins, losses))\n\n\n\nGame-by-Game Predictions with Machine Learning (Simple Metrics as Predictors)\nWe can try and make better predictions with a specific predictors. For now, I am going to start off with some fairly simple predictors. In the next section, I’ll run a model using some “higher-level” stats, but, for comparative purposes, I am going to start off with a model using simpler predictors. Keep in mind, there’s going to be a lot of error in this because I have to use the prior season’s statistics as predictors of the following season’s outcome. We know this doesn’t always work since some teams un-expectantly surge from year-to-year and others decline. Further, there is the problem of random “shocks” that really mess things up. For example, if Patrick Mahomes gets injuried in Week 3 for the 2024-2025 NFL season, I’m not so confident that this simple model is going to get the Chief’s standings right. Nonetheless, I’m just having fun here. I’m not claiming I’ve discovered the secret algorithm that will predict NFL games with 99% accuracy.\n\n# Import and Merge Features from 2021-2023 Play-by-Play Data\npbp_stats &lt;- load_pbp(2021:2023)\n\n# Collapse to the Game-Level\n\n\n# Train Model\n\n# Cross Validation\n\n# Forecast 2024 Wins (Pass Predicted Probabilities Into nflseedR)\n\n# Put This Information Into a Table\n\n\n\nGame-by-Game Predictions with Machine Learning (Advanced Metrics as Predictors)\n\n# Import and Merge Features\n\n# Train Model\n\n# Cross Validation\n\n# Forecast 2024 Wins (Pass Predicted Probabilities Into nflseedR)\n\n# Put This Information Into a Table\n\n\n\nComparing All Predictions (Reveal How I Did)"
  }
]