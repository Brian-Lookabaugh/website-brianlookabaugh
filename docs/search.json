[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brian Lookabaugh",
    "section": "",
    "text": "Greetings and welcome to my personal website! My name is Brian Lookabaugh and I am a Research Analyst at Fors Marsh. In my position, I leverage my skills in data analysis and statistical modeling to solve a variety of business questions. These include descriptive questions (creating visualizations to communicate what data says), predictive questions (utilizing machine learning to predict outcomes and forecast), and causal questions (drawing on my background in causal inference and experiment/quasi-experimental design to answer questions such as “did X have an impact on Y?”).\n\nOutside of my professional role, I routinely refine and expand my methodological toolkit by researching new methods and applying my skill set to other interests of mine (such as studying the NFL through a data science-lens). You can find some of these passion projects under the “Blog” section of this site. If you have any questions about my research, please feel free to reach out to me!"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "My personal research covers the intersection of causal inference, quasi-experimental design, and machine learning on a variety of topics that I find interesting, including (but not limited to): peace and conflict, democracy and elections, development, and the NFL (professional American football)."
  },
  {
    "objectID": "research/index.html#dissertation",
    "href": "research/index.html#dissertation",
    "title": "Research",
    "section": "Dissertation",
    "text": "Dissertation\n\n“Rethinking the Study of Conflict and Peace: Making Causal Inferences in Quantitative Conflict and Peace Research” \n\nManuscript \nCode (Chapter 2) \nCode (Chapter 3)"
  },
  {
    "objectID": "resume/index.html",
    "href": "resume/index.html",
    "title": "Brian Lookabaugh",
    "section": "",
    "text": "Download"
  },
  {
    "objectID": "blog/2024/roadtrip-replication/index.html",
    "href": "blog/2024/roadtrip-replication/index.html",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "",
    "text": "One of the primary goals of science is to examine causal relationships. Anytime a researcher asks a question like, “how does \\(X\\) impact \\(Y\\)?” or “do changes in \\(X\\) cause a change in \\(Y\\)?” that researcher is at the very beginning of a causal research design. Unfortunately, asking causal questions is a lot easier than answering them.1\nIt would be great if a researcher could simply look for a correlation between \\(X\\) and \\(Y\\) and determine whether \\(X\\) causes a change in \\(Y\\). However, inferring causation from a bi-variable test or a scatterplot is very, very poor practice. One of the biggest reasons why we can’t do this is because of confounding, which refers to things that cause some change in both \\(X\\) and \\(Y\\) (in notation: \\(X\\) \\(\\leftarrow\\) \\(Z\\) \\(\\rightarrow\\) \\(Y\\)) and, if not accounted for, will result in a misleading picture on the relationship between \\(X\\) and \\(Y\\). A somewhat canonical example to illustrate the problem of un-adjusted confounding is the relationship between ice cream sales (\\(X\\)) and shark attacks (\\(Y\\)).\n\n\nCode\n# Create Simulated Data\ndays &lt;- 365 # Number of Days in a Year\ntemp &lt;- pmin(pmax(rnorm(days, mean = 70, sd = 10), 30), 100) # Temperature\nshark &lt;- 0.5 + 0.1 * (temp - 70) + rnorm(days, mean = 0.5, sd = 0.5) # Shark Attacks\nshark &lt;- pmax(shark, 0) # Lowest Shark Attacks Can Go Is Zero\nshark &lt;- floor(shark) # Round This Down (There Can't Be Any 0.5 Shark Attacks)\nice &lt;- 15000 + 250 * (temp - 70) + rnorm(days, mean = 2500, sd = 500) # Ice Cream Sales with Random Variation\nsim &lt;- data.frame(days, temp, shark, ice) # Combine Data\n\n# Create a Scatter Plot\nggplot(sim, aes(x = ice, y = shark)) + \n  geom_point() + \n  labs(x = \"Ice Cream Sales per Day\", y = \"Shark Attacks per Day\", title = \"\") + \n  ylim(0, 4) +\n  blog_theme()\n\n\n\n\n\n\n\n\n\nThis plot is why we don’t infer causation from a bi-variable relationship. (This plot also uses totally fake data and it’s only here to serve as a theoretical example… Sharks really don’t attack this many people annually, but I really don’t like them so ¯\\_(ツ)_/¯ ). If we did, then we could conclude one should never risk swimming in the ocean after consuming ice cream. However, as you can see in the following graph, once we take temperature into account, the ice cream sales-shark attack-pipeline theory is certainly much less compelling. However, the point remains. If we were to remove all of the variation in the relationship between \\(X\\) and \\(Y\\) that is explained by the confounders, then the bi-variable correlation between \\(X\\) and \\(Y\\) would be the causal effect.2\n\n\nCode\nggplot(sim, aes(x = ice, y = shark, color = temp)) + \n  geom_point() + \n  labs(x = \"Ice Cream Sales per Day\", y = \"Shark Attacks per Day\", \n       title = \"\", color = \"Temperature\") + \n  scale_color_gradientn(colors = c(\"blue\", \"white\", \"red\"), limits = c(30, 100)) +  \n  ylim(0, 4) +\n  blog_theme()\n\n\n\n\n\n\n\n\n\nIn an ideal world, a researcher is able to utilize a randomized experiment to answer their causal question. Randomized experiments are incredibly valuable because the “treatment” (also known as “\\(X\\)”, the independent variable of interest, the exposure, etc.) is randomly allocated across the participants/units in the study. If treatment is randomly allocated then we’ve taken care of our confounders because \\(Z\\) \\(\\rightarrow\\) \\(X\\) is no longer true. The only thing that impacts \\(X\\) is pure chance (randomization). Sure, participants/units have characteristics that might make them more or less likely to respond to treatment in a certain way. But we don’t need to control for this because those same individuals are just as likely to be in the control group because pure chance determined their treatment status. Therefore, while randomization does not allow us to estimate causal effects for each individual within a study, we can estimate causal effects on average for the “populations” they represent by comparing the average outcome (\\(Y\\)) between the two groups (treated and control).\nBut experiments are pretty rare and are practically hard to pull off. They take time to design and to administer. It’s certainly a lot easier to just download your favorite data set and plug variables into a regression model.3 In some cases, experiments are impossible to pull off. For example, my academic background is in the study of armed conflict and violence. If I want to run an experiment to evaluate the effect of democracy on civil violence… well, you can see where that gets very tricky. How am I supposed to randomly allocate which countries get to be democracies and which don’t? And this leads to the third point. Even if this bizarre experiment was possible and I had the political clout to pull that off, it would certainly not be very ethical.\nSo, absent experiments, we find ourselves in a less-than-desirable state. Because now, we have to manually identify, collect, and appropriately control for all confounders that the experiment otherwise would have taken care of for us via randomization. This really is not a small task at all if you sit and think about it. How do I know that I’ve identified all of the confounders? What if I can’t measure some of them? If I omit a confounder (or several) how can I know how much of an impact their omission had on my analysis? What if I control for a variable that isn’t a confounder? These are great questions and they highlight the reality that confounding will be a problem in your design which renders your original causal question incredibly difficult to reliably answer. I won’t be covering these problems in this blog, but tools like directed acyclic graphs (DAGs), simulation, and sensitivity analyses are very helpful and I would highly recommend spending some time to learn about them (although, none of these tools solve the problem of un-adjusted confounding and plugging as many control variables into your regression is almost always going to harm more than it will help).4\nRather than spending time on these serious problems, I am going to introduce another problem that is often under-appreciated and less discussed than other prominent topics in the causal inference literature. It turns out that when you’re examining multiple units (individuals, firms, schools, countries, etc.) over time, the analysis gets a bit more complicated and requires more robust solutions than what are often employed."
  },
  {
    "objectID": "blog/2024/roadtrip-replication/index.html#footnotes",
    "href": "blog/2024/roadtrip-replication/index.html#footnotes",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote: if you are already familiar with the core concepts of causal inference, feel free to skip down to the section where I start discussing time and why it messes things up.↩︎\nWell… kind of. There are actually a lot of other assumptions that you would need to check for first, like positivity, SUTVA, no measurement error, etc. (which will not be covered here in sufficient detail if you are not familiar with these topics). If you’re not super familiar with these topics, I highly recommend checking out Chatton and Rohrer 2024.↩︎\nI do not condone this attitude… never treat your regressions or research designs this way.↩︎\nHere are some good starting materials for DAGs, simulation, and sensitivity analyses: Rohrer 2018, Blair et al. 2023, Cinelli and Hazlett 2020.↩︎"
  },
  {
    "objectID": "blog/index.html#section",
    "href": "blog/index.html#section",
    "title": "Blog",
    "section": "2024",
    "text": "2024\n\n\n\n\n\n\n\n\n\n\nAn Introduction to Dynamic Causal Inference\n\n\n\n\n\n\ncausal inference\n\n\npanel data\n\n\ndags\n\n\n\nLearn the basics to making causal inferences with panel/longitudinal data.\n\n\n\n\n\nJuly 8, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2024/index.html",
    "href": "blog/2024/index.html",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "",
    "text": "Code\n# Load Libraries\npacman::p_load(\n  \"dplyr\", # Data Manipulation\n  \"ggplot2\", # Data Visualization\n  \"ggtext\", # Labels\n  \"dagitty\", # Creating DAGs\n  \"ggdag\", # Plotting DAGs\n  install = FALSE\n)\n\n# Define a Custom Theme - Taken From Andrew Heiss's Blogs\nblog_theme &lt;- function() {\n  theme_bw() +  # Start with theme_bw\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.background = element_rect(fill = \"white\", color = NA),\n      plot.title = element_text(face = \"bold\"),\n      axis.title = element_text(face = \"bold\"),\n      strip.text = element_text(face = \"bold\"),\n      strip.background = element_rect(fill = \"grey80\", color = NA),\n      legend.title = element_text(face = \"bold\")\n    )\n}"
  },
  {
    "objectID": "blog/2024/index.html#footnotes",
    "href": "blog/2024/index.html#footnotes",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote: if you are already familiar with the core concepts of causal inference, feel free to skip down to the section where I start discussing time and why it messes things up.↩︎\nWell… kind of. There are actually a lot of other assumptions that you would need to check for first, like positivity, SUTVA, no measurement error, etc. (which will not be covered here in sufficient detail if you are not familiar with these topics). If you’re not super familiar with these topics, I highly recommend checking out Chatton and Rohrer 2024.↩︎\nI do not condone this attitude… never treat your regressions or research designs this way.↩︎\nHere are some good starting materials for DAGs, simulation, and sensitivity analyses: Rohrer 2018, Blair et al. 2023, Cinelli and Hazlett 2020.↩︎"
  },
  {
    "objectID": "blog/2024/dynamic-causal-inference/index.html",
    "href": "blog/2024/dynamic-causal-inference/index.html",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "",
    "text": "Code\n# Load Libraries\npacman::p_load(\n  \"dplyr\", # Data Manipulation\n  \"ggplot2\", # Data Visualization\n  \"ggtext\", # Labels\n  \"dagitty\", # Creating DAGs\n  \"ggdag\", # Plotting DAGs\n  install = FALSE\n)\n\n# Define a Custom Theme - Taken From Andrew Heiss's Blogs\nblog_theme &lt;- function() {\n  theme_bw() +  # Start with theme_bw\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.background = element_rect(fill = \"white\", color = NA),\n      plot.title = element_text(face = \"bold\"),\n      axis.title = element_text(face = \"bold\"),\n      strip.text = element_text(face = \"bold\"),\n      strip.background = element_rect(fill = \"grey80\", color = NA),\n      legend.title = element_text(face = \"bold\")\n    )\n}"
  },
  {
    "objectID": "blog/2024/dynamic-causal-inference/index.html#footnotes",
    "href": "blog/2024/dynamic-causal-inference/index.html#footnotes",
    "title": "An Introduction to Dynamic Causal Inference",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote: if you are already familiar with the core concepts of causal inference, feel free to skip down to the section where I start discussing time and why it messes things up.↩︎\nWell… kind of. There are actually a lot of other assumptions that you would need to check for first, like positivity, SUTVA, no measurement error, etc. (which will not be covered here in sufficient detail if you are not familiar with these topics). If you’re not super familiar with these topics, I highly recommend checking out Chatton and Rohrer 2024.↩︎\nI do not condone this attitude… never treat your regressions or research designs this way.↩︎\nHere are some good starting materials for DAGs, simulation, and sensitivity analyses: Rohrer 2018, Blair et al. 2023, Cinelli and Hazlett 2020.↩︎"
  }
]